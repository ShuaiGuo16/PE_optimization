{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "470e6e6b-1c3d-479b-82d2-1d2c99a1e727",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "In this notebook, we generate candidate samples for the design variables. The purpose of the candidate samples is that the trained surrogate model can propose promising, feasible solutions from the candidate samples to facilitate downstream optimization task.\n",
    "\n",
    "Here, the key difference is that we do not sample Q1 and Q2 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b634ce7d-548a-4cfb-8ebe-eb7281900cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import qmc\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb1083e-a9f2-479a-8e9e-077388ca9a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "Ta = 25\n",
    "c_source = 50e-3\n",
    "d_source = 65e-3\n",
    "c_module = 61.4e-3\n",
    "d_module = 106e-3\n",
    "fan = 3\n",
    "\n",
    "# Generate samples\n",
    "data_length = 100000\n",
    "data_number = 6\n",
    "append_position_number = 1\n",
    "sampler = qmc.LatinHypercube(d=data_number)\n",
    "X = sampler.random(n=data_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92096b3d-8ae0-45a7-aa22-4ff3e21fd5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale X to the required ranges\n",
    "d_min, d_max = 5e-3, 30e-3\n",
    "d_sum = (d_max - d_min) * X[:, 0] + d_min\n",
    "\n",
    "b_min, b_max = 73.7e-3, 307e-3\n",
    "b_sum = (b_max - b_min) * X[:, 1] + b_min\n",
    "\n",
    "L_min, L_max = 127.2e-3, 530e-3\n",
    "L_sum = (L_max - L_min) * X[:, 2] + L_min\n",
    "\n",
    "c_min, c_max = 10e-3, 39e-3\n",
    "c_sum = (c_max - c_min) * X[:, 3] + c_min\n",
    "\n",
    "L_duct_min, L_duct_max = 20e-3, 50e-3\n",
    "L_duct_sum = (L_duct_max - L_duct_min) * X[:, 4] + L_duct_min\n",
    "\n",
    "n_min, n_max = 10, 50\n",
    "n_sum = np.round((n_max - n_min) * X[:, 5] + n_min).astype(int)\n",
    "\n",
    "data_sum = np.column_stack((d_sum, b_sum, L_sum, c_sum, L_duct_sum, n_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bf089a-a20b-451c-8ad6-c256f2c2425e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_design = []\n",
    "t_invalid = 0\n",
    "valid_position = defaultdict(list)\n",
    "\n",
    "# Derived parameters calculation\n",
    "for i in range(data_length):\n",
    "    if (i+1)%500 == 0:\n",
    "        print(f\"Processing {i+1} samples\")\n",
    "        \n",
    "    d, b, L, c, L_duct, n = data_sum[i]\n",
    "\n",
    "    t_min = 1e-3\n",
    "    t_max = b / n - 1e-3\n",
    "\n",
    "    if t_min > t_max:\n",
    "        t_invalid += 1\n",
    "    \n",
    "    else:\n",
    "        t = np.random.rand() * (t_max - t_min) + t_min\n",
    "\n",
    "        Xc_min = c_module / 2\n",
    "        Xc_max = b - c_module / 2\n",
    "        Yc_min = d_module / 2\n",
    "        Yc_max = L - d_module / 2\n",
    "\n",
    "        # Generate position samples \n",
    "        position_sampler = qmc.LatinHypercube(d=4)\n",
    "        positions = position_sampler.random(n=int(5000))\n",
    "\n",
    "        # Scale samples\n",
    "        positions[:, 0] = positions[:, 0]*(Xc_max-Xc_min)+ Xc_min;\n",
    "        positions[:, 1] = positions[:, 1]*(Yc_max-Yc_min)+ Yc_min;\n",
    "        positions[:, 2] = positions[:, 2]*(Xc_max-Xc_min)+ Xc_min;\n",
    "        positions[:, 3] = positions[:, 3]*(Yc_max-Yc_min)+ Yc_min;\n",
    "\n",
    "        # Check non-overlapping\n",
    "        xc1, yc1, xc2, yc2 = positions[:, 0], positions[:, 1], positions[:, 2], positions[:, 3]\n",
    "        non_overlapping = (np.abs(xc1 - xc2) > c_module) | (np.abs(yc1 - yc2) > d_module)\n",
    "\n",
    "        # Retain valid positions\n",
    "        valid_positions = positions[non_overlapping]\n",
    "        valid_position['b'].append(b)\n",
    "        valid_position['L'].append(L)\n",
    "        valid_position['valid_pos'].append(len(valid_positions))\n",
    "\n",
    "        # Compose the design variables\n",
    "        if len(valid_positions) > 0:\n",
    "            \n",
    "            if append_position_number == 1:\n",
    "                # Randomly pick 1 sample from the valid positions\n",
    "                random_index = np.random.randint(0, len(valid_positions))\n",
    "                selected_position = valid_positions[random_index]\n",
    "                result_design.append(np.concatenate((data_sum[i], [t], selected_position)))\n",
    "                \n",
    "            elif len(valid_positions) <= append_position_number:\n",
    "                for pos in valid_positions:\n",
    "                    # Append each valid position to the design\n",
    "                    result_design.append(np.concatenate((data_sum[i], [t], pos)))\n",
    "    \n",
    "            else:\n",
    "                # Perform clustering and append the centroid/closest to centroid positions\n",
    "                kmeans = KMeans(n_clusters=append_position_number, n_init=10, random_state=0).fit(valid_positions)\n",
    "                centers = kmeans.cluster_centers_\n",
    "                \n",
    "                # For each center, find the closest valid position\n",
    "                for center in centers:\n",
    "                    distances = np.sqrt(((valid_positions - center)**2).sum(axis=1))\n",
    "                    closest_index = np.argmin(distances)\n",
    "                    closest_position = valid_positions[closest_index]\n",
    "                    \n",
    "                    # Append the closest valid position to the design\n",
    "                    result_design.append(np.concatenate((data_sum[i], [t], closest_position)))\n",
    "\n",
    "result_design = np.array(result_design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a15d56-0f14-476e-ac4c-25a4027e1893",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(valid_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d996d8-0c8f-460f-92c7-507b728617ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Invalid t design: {t_invalid}/{data_length}\")\n",
    "print(f\"Invalid heat source position: {np.sum(df['valid_pos'] == 0)}/{len(df)}\")\n",
    "print(f\"Invalid heat source position ratio (%): {np.sum(df['valid_pos'] == 0)/len(df)*100:.3f}%\")\n",
    "print(f\"Remaining valid samples: {result_design.shape[0]}/{data_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204fecd3-e7d8-4a14-8477-a4d559856bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure dataframe\n",
    "design_df = pd.DataFrame(result_design)\n",
    "column_names = ['d', 'b', 'L', 'c', 'L_duct', 'n', 't', 'xc1', 'yc1', 'xc2', 'yc2']\n",
    "design_df.columns = column_names\n",
    "design_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f720e7b5-25d0-4485-8b39-6e6ec02f2a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the design samples\n",
    "design_df.to_csv(\"./Dataset/candidate_100000.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83758e77-9e08-48a3-a8fe-a1302b9cd593",
   "metadata": {},
   "source": [
    "#### Generate Q1 and Q2 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aadd660c-3b8c-4c50-9000-4ef5344eddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_min, Q_max = 50, 400 \n",
    "\n",
    "Q_sampler = qmc.LatinHypercube(d=2)\n",
    "Q = Q_sampler.random(n=50)\n",
    "Q = (Q_max-Q_min) * Q + Q_min\n",
    "\n",
    "swap = Q[:, 0] < Q[:, 1]\n",
    "Q[swap, 0], Q[swap, 1] = Q[swap, 1], Q[swap, 0].copy()\n",
    "\n",
    "Q_df = pd.DataFrame(Q)\n",
    "column_names = ['Q1', 'Q2']\n",
    "Q_df.columns = column_names\n",
    "Q_df.to_csv(\"./dataset/Q_test_locations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16599d70-dca2-438f-831b-da2aa3c9ff27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
