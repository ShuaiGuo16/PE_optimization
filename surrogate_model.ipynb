{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "979c2810",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "In this notebook, we attempt to build surrogate models for predicting the thermal resistance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b6f4ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "import sklearn.gaussian_process as gp\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, max_error\n",
    "\n",
    "# Custom Gaussian Process model\n",
    "GP_path = os.path.abspath(os.path.join('../../'))\n",
    "if GP_path not in sys.path:\n",
    "    sys.path.append(GP_path+\"\\\\GaussianProcess\")\n",
    "from GPInterpolator import GPInterpolator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea94f231",
   "metadata": {},
   "source": [
    "### 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a467ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pool: 9421\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./Dataset/TcTj_train.csv', header=None)\n",
    "df.columns = ['Q1', 'Q2', 'd', 'b', 'L', 'c', 'L_duct', 'n', 't', 'xc1', 'yc1', 'xc2', 'yc2', 'Tc', 'Tj', 'w']\n",
    "print(f\"Pool: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31e1bef4-04f0-43db-aa0c-9926c85a331f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[397.98,\n",
       " 381.19,\n",
       " 0.021736,\n",
       " 0.20004,\n",
       " 0.32107,\n",
       " 0.015976,\n",
       " 0.045993,\n",
       " 45.0,\n",
       " 0.0011509,\n",
       " 0.062429,\n",
       " 0.12079,\n",
       " 0.12857,\n",
       " 0.059733]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0, :-3].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f209a3a8-17ad-4aa7-b322-d54709c31e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "df = df[df.Tj<250].reset_index(drop=True)\n",
    "print(f\"Filtered training pool: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5f75df-f20d-403d-ac7e-f6592cb4a8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dedicated testing set\n",
    "df_test = pd.read_csv('./Dataset/TcTj_test.csv', header=None)\n",
    "df_test.columns = ['Q1', 'Q2', 'd', 'b', 'L', 'c', 'L_duct', 'n', 't', 'xc1', 'yc1', 'xc2', 'yc2', 'Tc', 'Tj', 'w']\n",
    "\n",
    "# Remove outliers\n",
    "df_test = df_test[df_test.Tj<250].reset_index(drop=True)\n",
    "print(f\"Filtered testing pol: {df_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4178b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_samples(df, train_num):\n",
    "   \n",
    "    # Create dataset\n",
    "    X = df.iloc[:, :-3].to_numpy()\n",
    "    y = df.iloc[:, -2].to_numpy()\n",
    "    \n",
    "    # Train-test split\n",
    "    if train_num < len(df):\n",
    "        test_size = 1-train_num/len(df)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    else:\n",
    "        X_train, y_train = X, y\n",
    "        X_test, y_test = None, None\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3055a43e",
   "metadata": {},
   "source": [
    "### 2. Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a07086",
   "metadata": {},
   "source": [
    "#### 2.1 Model specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bcc5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(model_type, X_train, y_train, hyperparams, GP_model=None):\n",
    "    \"\"\"This function is used for training ML models.\"\"\"\n",
    "    \n",
    "    # Construct pipeline\n",
    "    if model_type == 'Gaussian Process':\n",
    "        # Custom GP\n",
    "        model = Pipeline([\n",
    "            ('scaler', MinMaxScaler()),\n",
    "            ('regressor', GPInterpolator(**hyperparams[model_type]))\n",
    "        ])        \n",
    "        \n",
    "    elif model_type == 'Gaussian Process (sklearn)':\n",
    "        model = Pipeline([\n",
    "            ('scaler', MinMaxScaler()),\n",
    "            ('regressor', gp.GaussianProcessRegressor(**hyperparams[model_type]))\n",
    "        ])\n",
    "\n",
    "    elif model_type == 'XGBoost':\n",
    "        model = xgb.XGBRegressor(**hyperparams[model_type])\n",
    "    \n",
    "    else:\n",
    "        raise KeyError('Unrecognized model type!')\n",
    "    \n",
    "    # Fit the pipeline\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80d4761",
   "metadata": {},
   "source": [
    "#### 2.2 ML training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58670404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    \"\"\"This function is used for evaluating the ML models performance.\"\"\"\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    max_e = max_error(y_true, y_pred)\n",
    "    \n",
    "    percentage = np.abs(y_true-y_pred)/y_true\n",
    "    max_percentage = np.max(percentage)*100\n",
    "    max_percentage_loc = np.argmax(percentage)\n",
    "    mean_percentage = np.mean(percentage)*100\n",
    "    \n",
    "    return rmse, max_e, max_percentage, max_percentage_loc, mean_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0757f8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hyperparams = {\n",
    "    'XGBoost': {'n_estimators': 2000, 'max_depth': 5, 'learning_rate': 0.05, 'reg_lambda': 10,\n",
    "               'gamma': 0, 'subsample': 0.3, 'colsample_bytree': 1, 'random_state': 10, 'n_jobs': -1},\n",
    "    'Gaussian Process': {\n",
    "        'n_restarts': 20,\n",
    "        'kernel': 'Gaussian',\n",
    "        'trend': 'Const',\n",
    "        'opt': {'optimizer':'L-BFGS-B', 'jac': True}\n",
    "    },\n",
    "    'Gaussian Process (sklearn)': {\n",
    "        'kernel': gp.kernels.ConstantKernel(1.0, (1e-3, 1e3)) * gp.kernels.RBF(1.0, (1e-3, 1e3)),\n",
    "        'optimizer': 'fmin_l_bfgs_b',\n",
    "        'n_restarts_optimizer': 10,\n",
    "        'alpha': 1e-10,\n",
    "        'normalize_y': True,\n",
    "        'random_state': 10\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02b0052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, _, y_train, _ = create_samples(df, 9000)\n",
    "X_test, _, y_test, _ = create_samples(df_test, 9000)\n",
    "\n",
    "# Fit the model\n",
    "model_type = 'XGBoost'\n",
    "model = model_fit(model_type, X_train, y_train, model_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1280589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess the model\n",
    "if model_type == 'Gaussian Process':\n",
    "    y_pred, _ = model.predict(X_test)\n",
    "\n",
    "else:\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "rmse, max_e, max_per, _, mean_per = evaluate_model(y_test, y_pred)\n",
    "print(f\"RMSE: {rmse:.4f} / data std: {np.std(y_test):.4f}\")\n",
    "print(f\"Max Error: {max_e:.4f}\")\n",
    "print(f\"Max Percentage Error: {max_per:.2f}\")\n",
    "print(f\"Mean Percentage Error: {mean_per:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560f4aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the default font size\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "ax.plot(y_test, y_pred, 'o')\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "ax.set_title('Tjmax Calculation')\n",
    "ax.set_xlabel('Ground truth')\n",
    "ax.set_ylabel('Prediction')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34538230-223a-4dcf-9575-d805fff9e545",
   "metadata": {},
   "source": [
    "#### 2.3 Sensitivity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717c0c38-f880-4bea-8387-48005f348ee4",
   "metadata": {},
   "source": [
    "#### XGBoost feature importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983adefc-16a7-4b50-a7eb-a766cb6e4a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_booster().feature_names = ['Q1', 'Q2', 'd', 'b', 'L', 'c', 'L_duct', 'n', 't', 'xc1', 'yc1', 'xc2', 'yc2']\n",
    "feature_importance = model.get_booster().get_score(importance_type='gain')\n",
    "\n",
    "# Plotting feature importance\n",
    "xgb.plot_importance(model)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9645f98f-532a-477a-b90d-5600eb04abbc",
   "metadata": {},
   "source": [
    "#### Sobol indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0ce28b-f3a8-4a97-9115-f61517a8d406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SALib.sample import sobol as sobol_sample\n",
    "from SALib.analyze import sobol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b285112-4305-4cfd-9494-4da2bd7831a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_constraints(X):\n",
    "\n",
    "    # Dimension\n",
    "    c_module, d_module = 61.4e-3, 106e-3\n",
    "    \n",
    "    # Position\n",
    "    Xc_min = c_module / 2\n",
    "    Xc_max = X[3] - c_module / 2\n",
    "    Yc_min = d_module / 2\n",
    "    Yc_max = X[4] - d_module / 2\n",
    "    \n",
    "    con1 = X[8] < X[3] / X[7] - 1e-3     # For t\n",
    "    con2 = (X[-4] < Xc_max) and (X[-4] > Xc_min) and (X[-3] < Yc_max) and (X[-3] > Yc_min)\n",
    "    con3 = (X[-2] < Xc_max) and (X[-2] > Xc_min) and (X[-1] < Yc_max) and (X[-1] > Yc_min)\n",
    "    con4 = (np.abs(X[-4] - X[-2]) > c_module) | (np.abs(X[-3] - X[-1]) > d_module)\n",
    "    return con1 and con2 and con3 and con4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c43cac-f85c-4303-94f0-2d6dfaff2a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = []\n",
    "for feature in df.columns.to_list()[:-3]:\n",
    "    bounds.append([df[feature].to_numpy().min(), df[feature].to_numpy().max()])\n",
    "\n",
    "# Define your problem with the input variables\n",
    "problem = {\n",
    "    'num_vars': 13,  # Adjust the number of variables based on your model\n",
    "    'names': ['Q1', 'Q2', 'd', 'b', 'L', 'c', 'L_duct', 'n', 't', 'xc1', 'yc1', 'xc2', 'yc2'],  # Names of the variables\n",
    "    'bounds': bounds # Bounds for each variable, adjust accordingly\n",
    "}\n",
    "\n",
    "# Generate samples using the Saltelli sampler\n",
    "N = 16384\n",
    "\n",
    "# Check sensitivity indices\n",
    "index_type = \"ST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8072fd6-8d28-4fa6-8fa0-8cc93462b9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def evaluate_model(X):\n",
    "    predictions = model.predict(X)\n",
    "    return predictions\n",
    "\n",
    "# Generate samples as before\n",
    "samples = sobol_sample.sample(problem, N)\n",
    "\n",
    "# Switch Q1 & Q2 (Q1 always larger than Q2)\n",
    "swap = samples[:, 0] < samples[:, 1]\n",
    "samples[swap, 0], samples[swap, 1] = samples[swap, 1], samples[swap, 0].copy()\n",
    "\n",
    "# Swap locations as well\n",
    "samples[swap, -4], samples[swap, -2] = samples[swap, -2], samples[swap, -4].copy()\n",
    "samples[swap, -3], samples[swap, -1] = samples[swap, -1], samples[swap, -3].copy()\n",
    "\n",
    "# Rejection sampling\n",
    "valid_samples = np.array([s for s in samples if check_constraints(s)])\n",
    "\n",
    "# Evaluate the model using the XGBoost model\n",
    "expected_Y_size = (2*samples.shape[1]+2)\n",
    "num_full_sets = len(valid_samples) // expected_Y_size\n",
    "adjusted_valid_samples = valid_samples[:num_full_sets * expected_Y_size]\n",
    "Y = evaluate_model(adjusted_valid_samples)\n",
    "print(f\"True sample size: {len(Y)}/{N}\")\n",
    "\n",
    "# Proceed with Sobol analysis as before\n",
    "sobol_indices = sobol.analyze(problem, Y)\n",
    "sobol_indices = sobol_indices[index_type]\n",
    "variable_names = problem['names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131a050d-6a1e-4213-8c6a-aec7817bf26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and print first-order Sobol indices\n",
    "indices_with_names = list(zip(sobol_indices, variable_names))\n",
    "indices_with_names.sort(reverse=True)\n",
    "sorted_indices, sorted_names = zip(*indices_with_names)\n",
    "\n",
    "# Creating the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(sorted_indices)), sorted_indices, tick_label=sorted_names)\n",
    "plt.xlabel('Sobol Index')\n",
    "plt.title('Feature Sensitivity Ranking: Tjmax')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have the most sensitive feature on top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2611cd7c-3a03-4a82-b243-9438eec114cd",
   "metadata": {},
   "source": [
    "#### Weight sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320c0d12-33e1-417e-94f3-50001b20a6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def evaluate_weight(X):\n",
    "    # Properties\n",
    "    density_Al = 2700\n",
    "    Fan_height = 40e-3\n",
    "    Fan_Weight = 50.8e-3\n",
    "    N_fan = np.ceil(X[:, 3] / Fan_height)\n",
    "\n",
    "    # Weight calculation\n",
    "    w = density_Al*(X[:, 3]*X[:, 2]*X[:, 4]+X[:, 7]*(X[:, 5]*X[:, 8]*X[:, 4]))+ Fan_Weight*N_fan\n",
    "\n",
    "    return w\n",
    "\n",
    "# Generate samples as before\n",
    "samples = sobol_sample.sample(problem, N)\n",
    "\n",
    "# Rejection sampling\n",
    "valid_samples = np.array([s for s in samples if check_constraints(s)])\n",
    "\n",
    "# Evaluate the weights\n",
    "Y = evaluate_weight(valid_samples)\n",
    "\n",
    "# Proceed with Sobol analysis as before\n",
    "sobol_indices = sobol.analyze(problem, Y)\n",
    "sobol_indices = sobol_indices[index_type]\n",
    "variable_names = problem['names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e661ad-9dbc-44dc-8329-73e4bfcf1889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and print first-order Sobol indices\n",
    "indices_with_names = list(zip(sobol_indices, variable_names))\n",
    "indices_with_names.sort(reverse=True)\n",
    "sorted_indices, sorted_names = zip(*indices_with_names)\n",
    "\n",
    "# Creating the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(sorted_indices)), sorted_indices, tick_label=sorted_names)\n",
    "plt.xlabel('First-order Sobol Index')\n",
    "plt.title('Feature Sensitivity Ranking: Weight')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have the most sensitive feature on top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202df109-6671-4a19-9eb5-54838d9ac087",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
