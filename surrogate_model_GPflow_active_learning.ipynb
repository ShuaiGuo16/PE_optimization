{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "979c2810",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "In this notebook, we attempt to build surrogate models for predicting the thermal resistance. \n",
    "\n",
    "Here, we aim to train GP adaptively to approximate the Tjmax=175 limit state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b6f4ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shuai\\anaconda3\\envs\\SciML\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Shuai\\anaconda3\\envs\\SciML\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Shuai\\anaconda3\\envs\\SciML\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import qmc, norm\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, max_error, brier_score_loss\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from two_sources import thermal_distribution_maxT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea94f231",
   "metadata": {},
   "source": [
    "### 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "325db2b8-f135-478b-ac24-3e7d1179b110",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = (25, 50e-3, 65e-3, 61.4e-3, 106e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a467ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: 189\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('./dataset/train.csv')\n",
    "df_train.columns = ['Q1', 'Q2', 'd', 'b', 'L', 'c', 'L_duct', 'n', 't', 'xc1', 'yc1', 'xc2', 'yc2', 'Tc', 'Tj', 'w']\n",
    "print(f\"Training dataset: {df_train.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "049afbf4-4975-4391-b971-89d53c5438cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>d</th>\n",
       "      <th>b</th>\n",
       "      <th>L</th>\n",
       "      <th>c</th>\n",
       "      <th>L_duct</th>\n",
       "      <th>n</th>\n",
       "      <th>t</th>\n",
       "      <th>xc1</th>\n",
       "      <th>yc1</th>\n",
       "      <th>xc2</th>\n",
       "      <th>yc2</th>\n",
       "      <th>Tc</th>\n",
       "      <th>Tj</th>\n",
       "      <th>w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>355.139820</td>\n",
       "      <td>314.512342</td>\n",
       "      <td>0.029385</td>\n",
       "      <td>0.275739</td>\n",
       "      <td>0.154803</td>\n",
       "      <td>0.015783</td>\n",
       "      <td>0.023692</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.004294</td>\n",
       "      <td>0.233437</td>\n",
       "      <td>0.086118</td>\n",
       "      <td>0.080215</td>\n",
       "      <td>0.094712</td>\n",
       "      <td>129.300482</td>\n",
       "      <td>129.300482</td>\n",
       "      <td>4.988744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120.559225</td>\n",
       "      <td>105.816580</td>\n",
       "      <td>0.019954</td>\n",
       "      <td>0.102969</td>\n",
       "      <td>0.314078</td>\n",
       "      <td>0.034592</td>\n",
       "      <td>0.037687</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>0.065078</td>\n",
       "      <td>0.095670</td>\n",
       "      <td>0.045501</td>\n",
       "      <td>0.220070</td>\n",
       "      <td>54.411424</td>\n",
       "      <td>54.411424</td>\n",
       "      <td>3.433136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>301.009415</td>\n",
       "      <td>192.523188</td>\n",
       "      <td>0.023695</td>\n",
       "      <td>0.106825</td>\n",
       "      <td>0.413988</td>\n",
       "      <td>0.021935</td>\n",
       "      <td>0.036011</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.066218</td>\n",
       "      <td>0.306664</td>\n",
       "      <td>0.072154</td>\n",
       "      <td>0.088363</td>\n",
       "      <td>109.506004</td>\n",
       "      <td>109.506004</td>\n",
       "      <td>4.281630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>358.267488</td>\n",
       "      <td>349.143693</td>\n",
       "      <td>0.028807</td>\n",
       "      <td>0.118856</td>\n",
       "      <td>0.323420</td>\n",
       "      <td>0.011139</td>\n",
       "      <td>0.030872</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.005567</td>\n",
       "      <td>0.070974</td>\n",
       "      <td>0.062465</td>\n",
       "      <td>0.073593</td>\n",
       "      <td>0.205439</td>\n",
       "      <td>254.349741</td>\n",
       "      <td>254.349741</td>\n",
       "      <td>4.008711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>235.668062</td>\n",
       "      <td>157.249865</td>\n",
       "      <td>0.012980</td>\n",
       "      <td>0.175404</td>\n",
       "      <td>0.430567</td>\n",
       "      <td>0.016867</td>\n",
       "      <td>0.032250</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.003725</td>\n",
       "      <td>0.134959</td>\n",
       "      <td>0.102105</td>\n",
       "      <td>0.035446</td>\n",
       "      <td>0.251917</td>\n",
       "      <td>103.081174</td>\n",
       "      <td>103.081174</td>\n",
       "      <td>4.142581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>277.605592</td>\n",
       "      <td>80.214421</td>\n",
       "      <td>0.014407</td>\n",
       "      <td>0.166646</td>\n",
       "      <td>0.161272</td>\n",
       "      <td>0.010378</td>\n",
       "      <td>0.031142</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>0.034801</td>\n",
       "      <td>0.083433</td>\n",
       "      <td>0.122594</td>\n",
       "      <td>0.095787</td>\n",
       "      <td>119.963601</td>\n",
       "      <td>119.963601</td>\n",
       "      <td>1.589780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>360.339276</td>\n",
       "      <td>52.364956</td>\n",
       "      <td>0.019092</td>\n",
       "      <td>0.188851</td>\n",
       "      <td>0.371149</td>\n",
       "      <td>0.033252</td>\n",
       "      <td>0.035701</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>0.081036</td>\n",
       "      <td>0.108038</td>\n",
       "      <td>0.043768</td>\n",
       "      <td>0.266257</td>\n",
       "      <td>103.341218</td>\n",
       "      <td>103.341218</td>\n",
       "      <td>5.415417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>137.954796</td>\n",
       "      <td>96.679536</td>\n",
       "      <td>0.017386</td>\n",
       "      <td>0.180576</td>\n",
       "      <td>0.399115</td>\n",
       "      <td>0.036451</td>\n",
       "      <td>0.049493</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.054960</td>\n",
       "      <td>0.141772</td>\n",
       "      <td>0.121323</td>\n",
       "      <td>0.211342</td>\n",
       "      <td>56.296731</td>\n",
       "      <td>56.296731</td>\n",
       "      <td>6.870861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>82.656515</td>\n",
       "      <td>62.385292</td>\n",
       "      <td>0.024895</td>\n",
       "      <td>0.147052</td>\n",
       "      <td>0.374643</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.022346</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>0.040947</td>\n",
       "      <td>0.152328</td>\n",
       "      <td>0.099911</td>\n",
       "      <td>0.295579</td>\n",
       "      <td>56.164247</td>\n",
       "      <td>56.164247</td>\n",
       "      <td>5.968222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>327.722087</td>\n",
       "      <td>175.523727</td>\n",
       "      <td>0.027864</td>\n",
       "      <td>0.257463</td>\n",
       "      <td>0.244780</td>\n",
       "      <td>0.010018</td>\n",
       "      <td>0.040309</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.004768</td>\n",
       "      <td>0.112440</td>\n",
       "      <td>0.177019</td>\n",
       "      <td>0.180443</td>\n",
       "      <td>0.096359</td>\n",
       "      <td>134.067212</td>\n",
       "      <td>134.067212</td>\n",
       "      <td>6.170177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Q1          Q2         d         b         L         c    L_duct  \\\n",
       "0    355.139820  314.512342  0.029385  0.275739  0.154803  0.015783  0.023692   \n",
       "1    120.559225  105.816580  0.019954  0.102969  0.314078  0.034592  0.037687   \n",
       "2    301.009415  192.523188  0.023695  0.106825  0.413988  0.021935  0.036011   \n",
       "3    358.267488  349.143693  0.028807  0.118856  0.323420  0.011139  0.030872   \n",
       "4    235.668062  157.249865  0.012980  0.175404  0.430567  0.016867  0.032250   \n",
       "..          ...         ...       ...       ...       ...       ...       ...   \n",
       "184  277.605592   80.214421  0.014407  0.166646  0.161272  0.010378  0.031142   \n",
       "185  360.339276   52.364956  0.019092  0.188851  0.371149  0.033252  0.035701   \n",
       "186  137.954796   96.679536  0.017386  0.180576  0.399115  0.036451  0.049493   \n",
       "187   82.656515   62.385292  0.024895  0.147052  0.374643  0.018100  0.022346   \n",
       "188  327.722087  175.523727  0.027864  0.257463  0.244780  0.010018  0.040309   \n",
       "\n",
       "        n         t       xc1       yc1       xc2       yc2          Tc  \\\n",
       "0    44.0  0.004294  0.233437  0.086118  0.080215  0.094712  129.300482   \n",
       "1    49.0  0.001070  0.065078  0.095670  0.045501  0.220070   54.411424   \n",
       "2    43.0  0.001233  0.066218  0.306664  0.072154  0.088363  109.506004   \n",
       "3    16.0  0.005567  0.070974  0.062465  0.073593  0.205439  254.349741   \n",
       "4    17.0  0.003725  0.134959  0.102105  0.035446  0.251917  103.081174   \n",
       "..    ...       ...       ...       ...       ...       ...         ...   \n",
       "184  29.0  0.002216  0.034801  0.083433  0.122594  0.095787  119.963601   \n",
       "185  22.0  0.002112  0.081036  0.108038  0.043768  0.266257  103.341218   \n",
       "186  25.0  0.003293  0.054960  0.141772  0.121323  0.211342   56.296731   \n",
       "187  24.0  0.004692  0.040947  0.152328  0.099911  0.295579   56.164247   \n",
       "188  34.0  0.004768  0.112440  0.177019  0.180443  0.096359  134.067212   \n",
       "\n",
       "             Tj         w  \n",
       "0    129.300482  4.988744  \n",
       "1     54.411424  3.433136  \n",
       "2    109.506004  4.281630  \n",
       "3    254.349741  4.008711  \n",
       "4    103.081174  4.142581  \n",
       "..          ...       ...  \n",
       "184  119.963601  1.589780  \n",
       "185  103.341218  5.415417  \n",
       "186   56.296731  6.870861  \n",
       "187   56.164247  5.968222  \n",
       "188  134.067212  6.170177  \n",
       "\n",
       "[189 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef413e0d-18f2-4e05-a28e-2ec2b30e4d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing dataset: 5655\n"
     ]
    }
   ],
   "source": [
    "# Dedicated testing set\n",
    "df_test = pd.read_csv('./Dataset/test.csv')\n",
    "df_test.columns = ['Q1', 'Q2', 'd', 'b', 'L', 'c', 'L_duct', 'n', 't', 'xc1', 'yc1', 'xc2', 'yc2', 'Tc', 'Tj', 'w']\n",
    "print(f\"Testing dataset: {df_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1033871c-27f0-4262-bdd6-125fda094aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>d</th>\n",
       "      <th>b</th>\n",
       "      <th>L</th>\n",
       "      <th>c</th>\n",
       "      <th>L_duct</th>\n",
       "      <th>n</th>\n",
       "      <th>t</th>\n",
       "      <th>xc1</th>\n",
       "      <th>yc1</th>\n",
       "      <th>xc2</th>\n",
       "      <th>yc2</th>\n",
       "      <th>Tc</th>\n",
       "      <th>Tj</th>\n",
       "      <th>w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>356.395266</td>\n",
       "      <td>144.179828</td>\n",
       "      <td>0.027791</td>\n",
       "      <td>0.148169</td>\n",
       "      <td>0.142119</td>\n",
       "      <td>0.028676</td>\n",
       "      <td>0.024699</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>0.114664</td>\n",
       "      <td>0.080575</td>\n",
       "      <td>0.039811</td>\n",
       "      <td>0.062508</td>\n",
       "      <td>106.200898</td>\n",
       "      <td>106.200898</td>\n",
       "      <td>2.563658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>368.808646</td>\n",
       "      <td>235.799176</td>\n",
       "      <td>0.029227</td>\n",
       "      <td>0.169697</td>\n",
       "      <td>0.382787</td>\n",
       "      <td>0.014792</td>\n",
       "      <td>0.029531</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.074481</td>\n",
       "      <td>0.257127</td>\n",
       "      <td>0.068794</td>\n",
       "      <td>0.053503</td>\n",
       "      <td>120.544942</td>\n",
       "      <td>120.544942</td>\n",
       "      <td>6.738812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109.657702</td>\n",
       "      <td>56.113264</td>\n",
       "      <td>0.012565</td>\n",
       "      <td>0.204452</td>\n",
       "      <td>0.351198</td>\n",
       "      <td>0.022393</td>\n",
       "      <td>0.038982</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.038548</td>\n",
       "      <td>0.169999</td>\n",
       "      <td>0.134746</td>\n",
       "      <td>0.230745</td>\n",
       "      <td>52.631816</td>\n",
       "      <td>52.631816</td>\n",
       "      <td>4.076087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>290.565204</td>\n",
       "      <td>263.656203</td>\n",
       "      <td>0.008551</td>\n",
       "      <td>0.302306</td>\n",
       "      <td>0.495513</td>\n",
       "      <td>0.033503</td>\n",
       "      <td>0.032348</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.013610</td>\n",
       "      <td>0.115247</td>\n",
       "      <td>0.084058</td>\n",
       "      <td>0.068212</td>\n",
       "      <td>0.284671</td>\n",
       "      <td>119.094185</td>\n",
       "      <td>119.094185</td>\n",
       "      <td>14.845235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>323.457603</td>\n",
       "      <td>266.906140</td>\n",
       "      <td>0.008188</td>\n",
       "      <td>0.275833</td>\n",
       "      <td>0.410712</td>\n",
       "      <td>0.034486</td>\n",
       "      <td>0.023580</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.006791</td>\n",
       "      <td>0.051188</td>\n",
       "      <td>0.149818</td>\n",
       "      <td>0.055778</td>\n",
       "      <td>0.288429</td>\n",
       "      <td>130.464918</td>\n",
       "      <td>130.464918</td>\n",
       "      <td>11.169889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5650</th>\n",
       "      <td>210.270976</td>\n",
       "      <td>101.705695</td>\n",
       "      <td>0.015563</td>\n",
       "      <td>0.149852</td>\n",
       "      <td>0.186680</td>\n",
       "      <td>0.019318</td>\n",
       "      <td>0.022339</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.004959</td>\n",
       "      <td>0.047727</td>\n",
       "      <td>0.124352</td>\n",
       "      <td>0.110789</td>\n",
       "      <td>0.113483</td>\n",
       "      <td>96.448095</td>\n",
       "      <td>96.448095</td>\n",
       "      <td>2.199603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5651</th>\n",
       "      <td>352.871362</td>\n",
       "      <td>247.671890</td>\n",
       "      <td>0.015205</td>\n",
       "      <td>0.171416</td>\n",
       "      <td>0.219256</td>\n",
       "      <td>0.024036</td>\n",
       "      <td>0.044648</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.125921</td>\n",
       "      <td>0.140918</td>\n",
       "      <td>0.052202</td>\n",
       "      <td>0.159077</td>\n",
       "      <td>116.234587</td>\n",
       "      <td>116.234587</td>\n",
       "      <td>2.532587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5652</th>\n",
       "      <td>224.445837</td>\n",
       "      <td>155.860506</td>\n",
       "      <td>0.018345</td>\n",
       "      <td>0.168901</td>\n",
       "      <td>0.293893</td>\n",
       "      <td>0.026435</td>\n",
       "      <td>0.024752</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.135408</td>\n",
       "      <td>0.091815</td>\n",
       "      <td>0.040881</td>\n",
       "      <td>0.197082</td>\n",
       "      <td>82.777441</td>\n",
       "      <td>82.777441</td>\n",
       "      <td>3.358140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5653</th>\n",
       "      <td>149.993232</td>\n",
       "      <td>91.302898</td>\n",
       "      <td>0.005494</td>\n",
       "      <td>0.303702</td>\n",
       "      <td>0.392907</td>\n",
       "      <td>0.018186</td>\n",
       "      <td>0.026981</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.007834</td>\n",
       "      <td>0.224231</td>\n",
       "      <td>0.115229</td>\n",
       "      <td>0.073253</td>\n",
       "      <td>0.115265</td>\n",
       "      <td>92.013851</td>\n",
       "      <td>92.013851</td>\n",
       "      <td>3.990053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5654</th>\n",
       "      <td>65.375443</td>\n",
       "      <td>65.369401</td>\n",
       "      <td>0.028075</td>\n",
       "      <td>0.147492</td>\n",
       "      <td>0.340448</td>\n",
       "      <td>0.025753</td>\n",
       "      <td>0.048768</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>0.054558</td>\n",
       "      <td>0.133194</td>\n",
       "      <td>0.106276</td>\n",
       "      <td>0.253484</td>\n",
       "      <td>42.030314</td>\n",
       "      <td>42.030314</td>\n",
       "      <td>5.877670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5655 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Q1          Q2         d         b         L         c  \\\n",
       "0     356.395266  144.179828  0.027791  0.148169  0.142119  0.028676   \n",
       "1     368.808646  235.799176  0.029227  0.169697  0.382787  0.014792   \n",
       "2     109.657702   56.113264  0.012565  0.204452  0.351198  0.022393   \n",
       "3     290.565204  263.656203  0.008551  0.302306  0.495513  0.033503   \n",
       "4     323.457603  266.906140  0.008188  0.275833  0.410712  0.034486   \n",
       "...          ...         ...       ...       ...       ...       ...   \n",
       "5650  210.270976  101.705695  0.015563  0.149852  0.186680  0.019318   \n",
       "5651  352.871362  247.671890  0.015205  0.171416  0.219256  0.024036   \n",
       "5652  224.445837  155.860506  0.018345  0.168901  0.293893  0.026435   \n",
       "5653  149.993232   91.302898  0.005494  0.303702  0.392907  0.018186   \n",
       "5654   65.375443   65.369401  0.028075  0.147492  0.340448  0.025753   \n",
       "\n",
       "        L_duct     n         t       xc1       yc1       xc2       yc2  \\\n",
       "0     0.024699  33.0  0.002149  0.114664  0.080575  0.039811  0.062508   \n",
       "1     0.029531  49.0  0.001814  0.074481  0.257127  0.068794  0.053503   \n",
       "2     0.038982  44.0  0.001429  0.038548  0.169999  0.134746  0.230745   \n",
       "3     0.032348  18.0  0.013610  0.115247  0.084058  0.068212  0.284671   \n",
       "4     0.023580  32.0  0.006791  0.051188  0.149818  0.055778  0.288429   \n",
       "...        ...   ...       ...       ...       ...       ...       ...   \n",
       "5650  0.022339  17.0  0.004959  0.047727  0.124352  0.110789  0.113483   \n",
       "5651  0.044648  34.0  0.001521  0.125921  0.140918  0.052202  0.159077   \n",
       "5652  0.024752  24.0  0.001282  0.135408  0.091815  0.040881  0.197082   \n",
       "5653  0.026981  12.0  0.007834  0.224231  0.115229  0.073253  0.115265   \n",
       "5654  0.048768  48.0  0.001644  0.054558  0.133194  0.106276  0.253484   \n",
       "\n",
       "              Tc          Tj          w  \n",
       "0     106.200898  106.200898   2.563658  \n",
       "1     120.544942  120.544942   6.738812  \n",
       "2      52.631816   52.631816   4.076087  \n",
       "3     119.094185  119.094185  14.845235  \n",
       "4     130.464918  130.464918  11.169889  \n",
       "...          ...         ...        ...  \n",
       "5650   96.448095   96.448095   2.199603  \n",
       "5651  116.234587  116.234587   2.532587  \n",
       "5652   82.777441   82.777441   3.358140  \n",
       "5653   92.013851   92.013851   3.990053  \n",
       "5654   42.030314   42.030314   5.877670  \n",
       "\n",
       "[5655 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "929cf4d4-9fcf-41bc-8b73-d31a7bf59de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active learning pool: 9388\n"
     ]
    }
   ],
   "source": [
    "# Dedicated pool for active learning\n",
    "df_pool = pd.read_csv('./dataset/AL_train_10000.csv')\n",
    "df_pool.columns = ['Q1', 'Q2', 'd', 'b', 'L', 'c', 'L_duct', 'n', 't', 'xc1', 'yc1', 'xc2', 'yc2']\n",
    "print(f\"Active learning pool: {df_pool.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "492ffbdd-d128-40cb-8be2-a65d8f226cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>d</th>\n",
       "      <th>b</th>\n",
       "      <th>L</th>\n",
       "      <th>c</th>\n",
       "      <th>L_duct</th>\n",
       "      <th>n</th>\n",
       "      <th>t</th>\n",
       "      <th>xc1</th>\n",
       "      <th>yc1</th>\n",
       "      <th>xc2</th>\n",
       "      <th>yc2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>354.162049</td>\n",
       "      <td>209.973777</td>\n",
       "      <td>0.008376</td>\n",
       "      <td>0.105262</td>\n",
       "      <td>0.358018</td>\n",
       "      <td>0.024769</td>\n",
       "      <td>0.049020</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.048407</td>\n",
       "      <td>0.056408</td>\n",
       "      <td>0.037934</td>\n",
       "      <td>0.304392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>310.266548</td>\n",
       "      <td>304.103605</td>\n",
       "      <td>0.016987</td>\n",
       "      <td>0.252752</td>\n",
       "      <td>0.375389</td>\n",
       "      <td>0.025041</td>\n",
       "      <td>0.048750</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>0.176011</td>\n",
       "      <td>0.056698</td>\n",
       "      <td>0.104327</td>\n",
       "      <td>0.227647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>143.215680</td>\n",
       "      <td>90.987329</td>\n",
       "      <td>0.024670</td>\n",
       "      <td>0.087385</td>\n",
       "      <td>0.367372</td>\n",
       "      <td>0.011184</td>\n",
       "      <td>0.029552</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.032683</td>\n",
       "      <td>0.289248</td>\n",
       "      <td>0.049411</td>\n",
       "      <td>0.181909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>164.643507</td>\n",
       "      <td>157.346416</td>\n",
       "      <td>0.026123</td>\n",
       "      <td>0.167066</td>\n",
       "      <td>0.523121</td>\n",
       "      <td>0.024806</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.005343</td>\n",
       "      <td>0.104320</td>\n",
       "      <td>0.229971</td>\n",
       "      <td>0.041316</td>\n",
       "      <td>0.270856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>223.010215</td>\n",
       "      <td>162.737110</td>\n",
       "      <td>0.013772</td>\n",
       "      <td>0.212688</td>\n",
       "      <td>0.198952</td>\n",
       "      <td>0.022884</td>\n",
       "      <td>0.044573</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.162109</td>\n",
       "      <td>0.140386</td>\n",
       "      <td>0.056991</td>\n",
       "      <td>0.064584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9383</th>\n",
       "      <td>221.704797</td>\n",
       "      <td>140.655720</td>\n",
       "      <td>0.015763</td>\n",
       "      <td>0.177631</td>\n",
       "      <td>0.298198</td>\n",
       "      <td>0.036769</td>\n",
       "      <td>0.032717</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.003203</td>\n",
       "      <td>0.091877</td>\n",
       "      <td>0.237605</td>\n",
       "      <td>0.096537</td>\n",
       "      <td>0.054759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9384</th>\n",
       "      <td>348.057919</td>\n",
       "      <td>114.923554</td>\n",
       "      <td>0.011999</td>\n",
       "      <td>0.101835</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>0.032715</td>\n",
       "      <td>0.026921</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.004623</td>\n",
       "      <td>0.046143</td>\n",
       "      <td>0.196469</td>\n",
       "      <td>0.042999</td>\n",
       "      <td>0.057228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9385</th>\n",
       "      <td>332.899604</td>\n",
       "      <td>220.776222</td>\n",
       "      <td>0.010925</td>\n",
       "      <td>0.265895</td>\n",
       "      <td>0.254384</td>\n",
       "      <td>0.013308</td>\n",
       "      <td>0.049156</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.003604</td>\n",
       "      <td>0.159820</td>\n",
       "      <td>0.198348</td>\n",
       "      <td>0.159719</td>\n",
       "      <td>0.053509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9386</th>\n",
       "      <td>384.975128</td>\n",
       "      <td>311.977766</td>\n",
       "      <td>0.017512</td>\n",
       "      <td>0.142966</td>\n",
       "      <td>0.168872</td>\n",
       "      <td>0.027084</td>\n",
       "      <td>0.042955</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.004502</td>\n",
       "      <td>0.043461</td>\n",
       "      <td>0.095763</td>\n",
       "      <td>0.109446</td>\n",
       "      <td>0.059088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9387</th>\n",
       "      <td>179.533393</td>\n",
       "      <td>109.728200</td>\n",
       "      <td>0.021157</td>\n",
       "      <td>0.198912</td>\n",
       "      <td>0.253230</td>\n",
       "      <td>0.020686</td>\n",
       "      <td>0.040085</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.011267</td>\n",
       "      <td>0.050349</td>\n",
       "      <td>0.067670</td>\n",
       "      <td>0.121836</td>\n",
       "      <td>0.168196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9388 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Q1          Q2         d         b         L         c  \\\n",
       "0     354.162049  209.973777  0.008376  0.105262  0.358018  0.024769   \n",
       "1     310.266548  304.103605  0.016987  0.252752  0.375389  0.025041   \n",
       "2     143.215680   90.987329  0.024670  0.087385  0.367372  0.011184   \n",
       "3     164.643507  157.346416  0.026123  0.167066  0.523121  0.024806   \n",
       "4     223.010215  162.737110  0.013772  0.212688  0.198952  0.022884   \n",
       "...          ...         ...       ...       ...       ...       ...   \n",
       "9383  221.704797  140.655720  0.015763  0.177631  0.298198  0.036769   \n",
       "9384  348.057919  114.923554  0.011999  0.101835  0.298507  0.032715   \n",
       "9385  332.899604  220.776222  0.010925  0.265895  0.254384  0.013308   \n",
       "9386  384.975128  311.977766  0.017512  0.142966  0.168872  0.027084   \n",
       "9387  179.533393  109.728200  0.021157  0.198912  0.253230  0.020686   \n",
       "\n",
       "        L_duct     n         t       xc1       yc1       xc2       yc2  \n",
       "0     0.049020  40.0  0.001542  0.048407  0.056408  0.037934  0.304392  \n",
       "1     0.048750  22.0  0.005418  0.176011  0.056698  0.104327  0.227647  \n",
       "2     0.029552  35.0  0.001247  0.032683  0.289248  0.049411  0.181909  \n",
       "3     0.040541  18.0  0.005343  0.104320  0.229971  0.041316  0.270856  \n",
       "4     0.044573  31.0  0.005747  0.162109  0.140386  0.056991  0.064584  \n",
       "...        ...   ...       ...       ...       ...       ...       ...  \n",
       "9383  0.032717  33.0  0.003203  0.091877  0.237605  0.096537  0.054759  \n",
       "9384  0.026921  15.0  0.004623  0.046143  0.196469  0.042999  0.057228  \n",
       "9385  0.049156  33.0  0.003604  0.159820  0.198348  0.159719  0.053509  \n",
       "9386  0.042955  18.0  0.004502  0.043461  0.095763  0.109446  0.059088  \n",
       "9387  0.040085  10.0  0.011267  0.050349  0.067670  0.121836  0.168196  \n",
       "\n",
       "[9388 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae4178b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_samples(df, train_num):\n",
    "   \n",
    "    # Create dataset\n",
    "    X = df.iloc[:, :-3].to_numpy()\n",
    "    y = df.iloc[:, -2].to_numpy()\n",
    "    \n",
    "    # Train-test split\n",
    "    if train_num < len(df):\n",
    "        test_size = 1-train_num/len(df)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    else:\n",
    "        X_train, y_train = X, y\n",
    "        X_test, y_test = None, None\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7786479d-29b2-41fa-a8cc-43881cf99208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, _, y_train, _ = create_samples(df_train, len(df_train))\n",
    "X_test, _, y_test, _ = create_samples(df_test, len(df_test))\n",
    "X_pool = df_pool.to_numpy()\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3055a43e",
   "metadata": {},
   "source": [
    "### 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58670404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    \"\"\"This function is used for evaluating the ML models performance.\"\"\"\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    max_e = max_error(y_true, y_pred)\n",
    "    \n",
    "    percentage = np.abs(y_true-y_pred)/y_true\n",
    "    max_percentage = np.max(percentage)*100\n",
    "    max_percentage_loc = np.argmax(percentage)\n",
    "    mean_percentage = np.mean(percentage)*100\n",
    "    \n",
    "    return rmse, max_e, max_percentage, max_percentage_loc, mean_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c77e600-5d94-482a-8c7f-d61acd0d094a",
   "metadata": {},
   "source": [
    "#### GPflow setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9430bc04-3ad5-4c97-abf3-29fd8ebb0313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_length_scales(dim, n_restarts, initial_guess=None):\n",
    "    \n",
    "    # Random initial params\n",
    "    lb, ub = -2, 2\n",
    "    lhd = qmc.LatinHypercube(d=dim, seed=42).random(n_restarts)\n",
    "    lhd = (ub-lb)*lhd + lb\n",
    "    length_scales = 10**lhd\n",
    "\n",
    "    # Informed initial guess\n",
    "    if initial_guess is not None:\n",
    "        length_scales = np.vstack((length_scales, initial_guess))\n",
    "\n",
    "    return length_scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d895448b-23c8-4cf0-abf0-f8bdc8903a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, n_restarts=20, init_lengthscales=None, init_variance=None, trainable=True, verbose=True):\n",
    "    models = []\n",
    "    log_likelihoods = []\n",
    "    \n",
    "    # Generate initial guesses for length scale\n",
    "    length_scales = init_length_scales(X.shape[1], n_restarts, init_lengthscales)\n",
    "    if init_variance is None:\n",
    "        variance=np.var(y_train)\n",
    "    else:\n",
    "        variance=init_variance\n",
    "\n",
    "    if not trainable:\n",
    "        model = gpflow.models.GPR(\n",
    "            (X, y.reshape(-1, 1)),\n",
    "            kernel=gpflow.kernels.SquaredExponential(variance=variance, lengthscales=init_lengthscales),\n",
    "            mean_function=gpflow.functions.Polynomial(0),\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "    else:\n",
    "        with tf.device(\"CPU:0\"):\n",
    "            \n",
    "            for i, init in enumerate(length_scales):\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"Performing {i+1}-th optimization:\")\n",
    "    \n",
    "                # Set up the model\n",
    "                kernel = gpflow.kernels.SquaredExponential(variance=variance, lengthscales=init)\n",
    "                model = gpflow.models.GPR(\n",
    "                    (X, y.reshape(-1, 1)),\n",
    "                    kernel=kernel,\n",
    "                    mean_function=gpflow.functions.Polynomial(0),\n",
    "                )\n",
    "    \n",
    "                opt = gpflow.optimizers.Scipy()\n",
    "                opt.minimize(model.training_loss, model.trainable_variables, options=dict(maxiter=100))\n",
    "    \n",
    "                models.append(model)\n",
    "                log_likelihoods.append(model.log_marginal_likelihood().numpy())\n",
    "    \n",
    "        # Select the model with the highest log-marginal likelihood\n",
    "        best_model_index = np.argmax(log_likelihoods)\n",
    "        best_model = models[best_model_index]\n",
    "\n",
    "        return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d54367-b787-405b-9e85-d859152f8c36",
   "metadata": {},
   "source": [
    "#### Active learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2cdd6f-ae56-49f0-a719-8f7d021b06d1",
   "metadata": {},
   "source": [
    "Select diverse batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10cc91c9-a4c3-4bc1-b038-1cd44bc499b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_diverse_batch(samples, acq, batch_size=5, pre_filter=False):\n",
    "    \n",
    "    if pre_filter:\n",
    "        thred = np.quantile(acq, pre_filter)\n",
    "        filtered_indices = np.arange(len(samples))[acq>thred]\n",
    "        samples = samples[acq>thred]\n",
    "        acq = acq[acq>thred]\n",
    "    \n",
    "    else:\n",
    "        filtered_indices = np.arange(len(samples))\n",
    "        \n",
    "    # Perform weighted K-means clustering on the samples\n",
    "    kmeans = KMeans(n_clusters=batch_size, n_init=10, random_state=0).fit(samples, sample_weight=acq)\n",
    "    cluster_labels = kmeans.labels_\n",
    "\n",
    "    # Find the highest acquisition value sample in each cluster\n",
    "    selected_indices = []\n",
    "    for cluster_idx in range(batch_size):\n",
    "        cluster_indices = np.where(cluster_labels == cluster_idx)[0]\n",
    "        cluster_acquisition_values = acq[cluster_indices]\n",
    "        best_index_in_cluster = cluster_indices[np.argmax(cluster_acquisition_values)]\n",
    "        selected_indices.append(best_index_in_cluster)\n",
    "\n",
    "    return filtered_indices[selected_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7b335b-7437-446a-be22-3c9dab1da9cc",
   "metadata": {},
   "source": [
    "Acquisition function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50ea9b55-8617-471a-b68b-3dfe8d3fbdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquisition(model, candidate, limit_state_value=0, batch_mode=False, batch_size=None):\n",
    "\n",
    "    # Compute prediction variance\n",
    "    f_mean, f_var = model.predict_f(candidate, full_cov=False)\n",
    "    f_mean = f_mean.numpy().flatten()\n",
    "    f_var = f_var.numpy().flatten()\n",
    "\n",
    "    # Calculate U values\n",
    "    U_values = np.abs(f_mean-limit_state_value)/np.sqrt(f_var)\n",
    "\n",
    "    # Sample selection\n",
    "    if batch_mode:\n",
    "        # Batch selection mode\n",
    "        U_normalied = MinMaxScaler().fit_transform(1/U_values.reshape(-1, 1))\n",
    "        indices = select_diverse_batch(candidate, U_normalied.flatten(), batch_size=batch_size)\n",
    "    \n",
    "    else:\n",
    "        # Single point selection mode\n",
    "        indices = np.argmin(U_values)\n",
    "\n",
    "    return U_values, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7af04a1c-2a3a-439f-9bc7-30c982cf05e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_assessment(model, X_test, y_test, limit_state):\n",
    "    f_mean, f_var = model.predict_f(X_test, full_cov=False)\n",
    "    y_prob = norm.cdf(limit_state, loc=f_mean, scale=np.sqrt(f_var))\n",
    "    label = np.where(y_test > limit_state, 1, 0)\n",
    "    brier_score = brier_score_loss(label, 1-y_prob)\n",
    "    return brier_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72a411a1-c83d-443b-b0e3-3ed1db4c0d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial training dataset size: 189\n"
     ]
    }
   ],
   "source": [
    "# Initial samples \n",
    "print(f\"Initial training dataset size: {X_train.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c43c9ad-f0dc-4473-bcab-c97cb96a5a72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start 1th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 1: test brier score==>0.02397/0.019, U==>0.0002/2, index==>[1599  343 8302 7233 2622 6986  799 9203 2703 1135]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 2th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 2: test brier score==>0.02374/0.019, U==>0.0003/2, index==>[3772 7480 8266 1394 3099 4373 3343 8065 8472  619]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 3th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 3: test brier score==>0.02319/0.019, U==>0.0001/2, index==>[3526 7806 3428 1716 8937 2694 6122 8723 5487 2284]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 4th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 4: test brier score==>0.01999/0.019, U==>0.0073/2, index==>[2624 2704 3746 6083 6941 2345  468 2932 3767 2094]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 5th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 5: test brier score==>0.01910/0.019, U==>0.0121/2, index==>[1519  481 4892 6907 2672 4905 8745 2918 1006 1926]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 6th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 6: test brier score==>0.01874/0.019, U==>0.0063/2, index==>[4933 5393 2176 1977 5627 2715 5366 7004 2879 7455]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 7th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 7: test brier score==>0.02000/0.019, U==>0.0166/2, index==>[1886 9303 6386 5544 5204 4952 8276 9300 6118 9122]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 8th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 8: test brier score==>0.01859/0.019, U==>0.0014/2, index==>[4635 4947  717 1515 3808 8474 1044 7007 7927  630]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 9th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 9: test brier score==>0.01849/0.019, U==>0.0024/2, index==>[9172 2508 3824 8147 1359  106 8528 4482 2658 1641]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 10th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 10: test brier score==>0.01824/0.019, U==>0.0112/2, index==>[5717 3597 5159 5500 1436 5849 1724 3884 5708 1009]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 11th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 11: test brier score==>0.01770/0.019, U==>0.0032/2, index==>[3533 3174 8934 4817  162 1889  253 2554  636   29]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 12th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 12: test brier score==>0.01755/0.019, U==>0.0035/2, index==>[ 537 1108 7301 4215 3935 9018 6410 3004  747 2498]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 13th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 13: test brier score==>0.01746/0.019, U==>0.0025/2, index==>[4621 4486 9226 7609 3676 4872 8958 6408 2802 6182]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 14th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 14: test brier score==>0.01739/0.019, U==>0.0034/2, index==>[2483 6915 4368 1364 1081 5824  885 2082 4063 8447]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 15th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 15: test brier score==>0.01661/0.019, U==>0.0104/2, index==>[2234 6711 5469  500 8456 2344 3503 1315  547 6412]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 16th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 16: test brier score==>0.01771/0.019, U==>0.0274/2, index==>[4396 7360 2408 1468 7203 5864 8180 8674 2147 1256]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 17th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 17: test brier score==>0.01686/0.019, U==>0.0078/2, index==>[2585    7  969 5986 8065 7962 2554 8544  360  921]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 18th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 18: test brier score==>0.01611/0.019, U==>0.0232/2, index==>[2325 1634 3859 7527 8976 1475 5561 2775  236 4213]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 19th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 19: test brier score==>0.01753/0.019, U==>0.0078/2, index==>[4608 7461 3170 8491 9052 3933 4807 3750 6446 9108]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 20th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 20: test brier score==>0.01759/0.019, U==>0.0468/2, index==>[ 346 3451  790 7447 1109 6818 8202 2753 2821 5445]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 21th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 21: test brier score==>0.01778/0.019, U==>0.0102/2, index==>[6846 1566 1824  134 6304 8331 2582 6038 1692 2736]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 22th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 22: test brier score==>0.01844/0.019, U==>0.0058/2, index==>[6126 8046 2744 8614  596 3254  673 5068 7612 7846]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 23th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 23: test brier score==>0.01618/0.019, U==>0.0802/2, index==>[ 727 8558 6564 6565 7497 2605  776 7975 1676 8066]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 24th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 24: test brier score==>0.01586/0.019, U==>0.0602/2, index==>[ 471  545 5440 5853 4029 6763 2393 3961 4562 7367]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 25th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 25: test brier score==>0.01686/0.019, U==>0.0163/2, index==>[1522 4679 6956  427 8875 2652 6818 4038 4977 7047]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 26th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 26: test brier score==>0.01577/0.019, U==>0.1426/2, index==>[1533 8105 8465 3387 7198 8963  234 8794 9084 1868]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 27th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 27: test brier score==>0.01515/0.019, U==>0.0880/2, index==>[4426 1521 2918 9088  303 5859 8383 2442 2624 1655]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 28th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 28: test brier score==>0.01581/0.019, U==>0.0500/2, index==>[8367 5302 8095  844 1069 2627 6103 7462  638 7445]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 29th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 29: test brier score==>0.01613/0.019, U==>0.1083/2, index==>[7311 3605 1969 1673  530 6836 6356 8668 1543 7772]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 30th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 30: test brier score==>0.01586/0.019, U==>0.1976/2, index==>[7718 5776 1196 8523 7306 7362 2459 3570  871 5203]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 31th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 31: test brier score==>0.01566/0.019, U==>0.2101/2, index==>[6345 4518 5975 4529 1656 8159 7019 4598  526 2396]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 32th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 32: test brier score==>0.01555/0.019, U==>0.0006/2, index==>[1080 6953 1158 6029 1160 5545 5763 3350 1772  935]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 33th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 33: test brier score==>0.01541/0.019, U==>0.0243/2, index==>[1380 3380 4656 4522 8352 1580 5768 4261 8818 4792]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 34th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 34: test brier score==>0.01545/0.019, U==>0.1877/2, index==>[3061  401 3942 2262 3647 4453 1399 1607 3718 5225]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 35th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 35: test brier score==>0.01511/0.019, U==>0.2165/2, index==>[6339 8472 6593 6389  174 3931 4753 2930 4094 5658]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 36th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 36: test brier score==>0.01470/0.019, U==>0.1407/2, index==>[6614 3106 6519 7276 6057 1327 7210 7522 3852 5408]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 37th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 37: test brier score==>0.01499/0.019, U==>0.0087/2, index==>[3170 2322 8867 5151 6519 4233 4558 5730 6332 4261]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 38th learning iteration:\n",
      "Bad fitting. Refit the data:\n",
      "Good fitting. Proceed:\n",
      "Iter 38: test brier score==>0.01541/0.019, U==>0.0599/2, index==>[ 921 5609 7023 7045 8550 4696  626 8377 4650 5994]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 39th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 39: test brier score==>0.01502/0.019, U==>0.1131/2, index==>[2675 4527 2172 1488 5415 2690 5426 2936 2434 4049]\n",
      "Calculating Tj values.\n",
      "Calculation compleed.\n",
      "Start 40th learning iteration:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m     model \u001b[38;5;241m=\u001b[39m fit(X_train_scaled, y_train, n_restarts\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# model = fit(X_train_scaled, y_train, n_restarts=20, verbose=False)\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_restarts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_lengthscales\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_lengthscales\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                \u001b[49m\u001b[43minit_variance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_variance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 2-Check fitting results\u001b[39;00m\n\u001b[0;32m     18\u001b[0m f_mean, _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_f(scaler\u001b[38;5;241m.\u001b[39mtransform(X_test), full_cov\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[13], line 38\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(X, y, n_restarts, init_lengthscales, init_variance, trainable, verbose)\u001b[0m\n\u001b[0;32m     31\u001b[0m model \u001b[38;5;241m=\u001b[39m gpflow\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mGPR(\n\u001b[0;32m     32\u001b[0m     (X, y\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)),\n\u001b[0;32m     33\u001b[0m     kernel\u001b[38;5;241m=\u001b[39mkernel,\n\u001b[0;32m     34\u001b[0m     mean_function\u001b[38;5;241m=\u001b[39mgpflow\u001b[38;5;241m.\u001b[39mfunctions\u001b[38;5;241m.\u001b[39mPolynomial(\u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m     35\u001b[0m )\n\u001b[0;32m     37\u001b[0m opt \u001b[38;5;241m=\u001b[39m gpflow\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mScipy()\n\u001b[1;32m---> 38\u001b[0m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m models\u001b[38;5;241m.\u001b[39mappend(model)\n\u001b[0;32m     41\u001b[0m log_likelihoods\u001b[38;5;241m.\u001b[39mappend(model\u001b[38;5;241m.\u001b[39mlog_marginal_likelihood()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SciML\\lib\\site-packages\\gpflow\\optimizers\\scipy.py:152\u001b[0m, in \u001b[0;36mScipy.minimize\u001b[1;34m(self, closure, variables, method, step_callback, compile, allow_unused_variables, tf_fun_args, track_loss_history, **scipy_kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m     callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_history_callback_func(func, history, scipy_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    150\u001b[0m     scipy_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callback\n\u001b[1;32m--> 152\u001b[0m opt_result \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39moptimize\u001b[38;5;241m.\u001b[39mminimize(\n\u001b[0;32m    153\u001b[0m     func, initial_params, jac\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, method\u001b[38;5;241m=\u001b[39mmethod, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscipy_kwargs\n\u001b[0;32m    154\u001b[0m )\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m track_loss_history:\n\u001b[0;32m    157\u001b[0m     opt_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss_history\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m history\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SciML\\lib\\site-packages\\scipy\\optimize\\_minimize.py:713\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    711\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 713\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    714\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    716\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    717\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SciML\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:369\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    363\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 369\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    372\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SciML\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:296\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SciML\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:262\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SciML\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:163\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SciML\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:145\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SciML\\lib\\site-packages\\scipy\\optimize\\_optimize.py:78\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m     77\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SciML\\lib\\site-packages\\scipy\\optimize\\_optimize.py:72\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 72\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SciML\\lib\\site-packages\\gpflow\\optimizers\\scipy.py:217\u001b[0m, in \u001b[0;36mScipy.eval_func.<locals>._eval\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_eval\u001b[39m(x: AnyNDArray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[AnyNDArray, AnyNDArray]:\n\u001b[1;32m--> 217\u001b[0m     loss, grad \u001b[38;5;241m=\u001b[39m \u001b[43m_tf_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64), grad\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SciML\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SciML\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SciML\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 877\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SciML\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SciML\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SciML\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SciML\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SciML\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SciML\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_iter = 100\n",
    "U_hist, test_brier_scores = [], []\n",
    "Tjmax = 175\n",
    "\n",
    "for i in range(n_iter):\n",
    "    print(f\"Start {i+1}th learning iteration:\")\n",
    "\n",
    "    # 1-GP model training and predicting\n",
    "    if i == 0:\n",
    "        model = fit(X_train_scaled, y_train, n_restarts=20, verbose=False)\n",
    "\n",
    "    else:\n",
    "        # model = fit(X_train_scaled, y_train, n_restarts=20, verbose=False)\n",
    "        model = fit(X_train_scaled, y_train, n_restarts=5, init_lengthscales=init_lengthscales, \n",
    "                    init_variance=init_variance, verbose=False)\n",
    "\n",
    "    # 2-Check fitting results\n",
    "    f_mean, _ = model.predict_f(scaler.transform(X_test), full_cov=False)\n",
    "    has_nan = tf.reduce_any(tf.math.is_nan(f_mean)).numpy()\n",
    "    counter = 0\n",
    "    while has_nan:\n",
    "        print(f\"Bad fitting. Refit the data:\")\n",
    "        counter += 1\n",
    "        model = fit(X_train_scaled, y_train, n_restarts=5, verbose=False)\n",
    "        f_mean, _ = model.predict_f(scaler.transform(X_test), full_cov=False)\n",
    "        has_nan = tf.reduce_any(tf.math.is_nan(f_mean)).numpy()\n",
    "\n",
    "        if counter > 4:\n",
    "            print(f\"Fallback to parameters from last iteration:\")\n",
    "            model = fit(X_train_scaled, y_train, n_restarts=1, init_lengthscales=init_lengthscales.flatten(), \n",
    "                        init_variance=init_variance, trainable=False, verbose=False)\n",
    "            f_mean, _ = model.predict_f(scaler.transform(X_test), full_cov=False)\n",
    "            has_nan = tf.reduce_any(tf.math.is_nan(f_mean)).numpy()\n",
    "\n",
    "    print(f\"Good fitting. Proceed:\")\n",
    "\n",
    "    # 3-Model assessment\n",
    "    brier_score = confidence_assessment(model, scaler.transform(X_test), y_test, Tjmax)\n",
    "    test_brier_scores.append(brier_score)\n",
    "\n",
    "    # 4-Acquisition\n",
    "    X_pool_scaled = scaler.transform(X_pool)\n",
    "    U_values, indices = acquisition(model, X_pool_scaled, limit_state_value=175, batch_mode=True, batch_size=10)\n",
    "    target = np.min(U_values[indices])\n",
    "    U_hist.append(target)\n",
    "    print(f\"Iter {i+1}: test brier score==>{brier_score:.5f}/{0.019}, U==>{target:.4f}/2, index==>{indices}\")\n",
    "\n",
    "    if target >= 2:\n",
    "        break\n",
    "\n",
    "    # 5-Updating\n",
    "    X_train = np.vstack((X_train, X_pool[indices]))\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "    # Calculating Tj\n",
    "    print(f\"Calculating Tj values.\")\n",
    "    response = []\n",
    "    for sample_index in indices:\n",
    "        Tmax, _ = thermal_distribution_maxT(X_pool[sample_index], Data)\n",
    "        response.append(Tmax)\n",
    "    y_train = np.append(y_train, np.array(response))\n",
    "    print(f\"Calculation compleed.\")\n",
    "\n",
    "    # Update pool\n",
    "    X_pool = np.delete(X_pool, obj=indices, axis=0)\n",
    "\n",
    "    # Update initial guess\n",
    "    init_lengthscales = model.kernel.lengthscales.numpy().reshape(1, -1)\n",
    "    init_variance = model.kernel.variance.numpy().flatten()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d3249a-ee05-4fb1-b764-8f6fb6e67bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "import pickle\n",
    "with open('AL_model_params.pickle', 'wb') as handle:\n",
    "    pickle.dump(gpflow.utilities.parameter_dict(model), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Save training data\n",
    "np.save('AL_X_train.npy', X_train)\n",
    "np.save('AL_y_train.npy', y_train)\n",
    "\n",
    "# Save history\n",
    "df = pd.DataFrame({\"U\": np.array(U_hist), \"brier_scores\": np.array(test_brier_scores)})\n",
    "df['benchmark'] = 0.01039\n",
    "df.to_csv(\"AL_history.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfdc6d8-19fe-41d1-8a71-e7f09771fadf",
   "metadata": {},
   "source": [
    "#### Propose solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ff05a9-e256-41c9-b0a1-7b4f94f9889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidates = pd.read_csv('./Dataset/candidates.csv')\n",
    "df_candidates.columns = ['d', 'b', 'L', 'c', 'L_duct', 'n', 't', 'xc1', 'yc1', 'xc2', 'yc2']\n",
    "print(f\"PCandidate pool: {df_candidates.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3439ccb-e2ec-43a3-a673-4ac3abcc4050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_weight(X):\n",
    "    # Properties\n",
    "    density_Al = 2700\n",
    "    Fan_height = 40e-3\n",
    "    Fan_Weight = 50.8e-3\n",
    "    N_fan = np.ceil(X[:, 3] / Fan_height)\n",
    "\n",
    "    # Weight calculation\n",
    "    w = density_Al*(X[:, 3]*X[:, 2]*X[:, 4]+X[:, 7]*(X[:, 5]*X[:, 8]*X[:, 4]))+ Fan_Weight*N_fan\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebc86f7-c9e7-4733-a132-4982dd7f1e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_df = pd.read_csv('./Dataset/Q_test_locations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623be34c-abcf-4c91-9f29-f17469b20900",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (Q1, Q2) in enumerate(zip(Q_df['Q1'].to_numpy(), Q_df['Q2'].to_numpy())):\n",
    "\n",
    "    print(f\"Handling {i+1}th condition:\")\n",
    "    \n",
    "    # Compile feature samples\n",
    "    Q1_array, Q2_array = Q1*np.ones((df_candidates.shape[0], 1)), Q2*np.ones((df_candidates.shape[0], 1))\n",
    "    X_candidates = df_candidates.to_numpy()\n",
    "    X_candidates = np.hstack((Q1_array, Q2_array, X_candidates))\n",
    "    X_candidates_scaled = scaler.transform(X_candidates)\n",
    "\n",
    "    # GP prediction\n",
    "    f_mean, f_var = model.predict_f(X_candidates_scaled, full_cov=False)\n",
    "    f_mean = f_mean.numpy().flatten()\n",
    "    f_var = f_var.numpy().flatten()\n",
    "\n",
    "    # Utility\n",
    "    Tjmax = 175\n",
    "    likelihood = norm.cdf(Tjmax, loc=f_mean, scale=np.sqrt(f_var))\n",
    "    w = evaluate_weight(X_candidates)\n",
    "    utility = likelihood*1/w\n",
    "\n",
    "    # Sort candidates\n",
    "    df = pd.DataFrame(X_candidates)\n",
    "    df.columns = ['Q1', 'Q2', 'd', 'b', 'L', 'c', 'L_duct', 'n', 't', 'xc1', 'yc1', 'xc2', 'yc2']\n",
    "    df['weight'] = w\n",
    "    df['pred_T'] = f_mean\n",
    "    df['utility'] = utility\n",
    "    df_sorted = df.sort_values(by='utility', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Output results\n",
    "    df_reduced = df_sorted.iloc[:20, :].reset_index(drop=True)\n",
    "    df_reduced.to_csv(f\"Exp_{i+1}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a585b1f-78a5-4e02-8b64-a59777b9be1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
