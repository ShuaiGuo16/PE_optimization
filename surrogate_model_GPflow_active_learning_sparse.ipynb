{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "979c2810",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "In this notebook, we attempt to build surrogate models for predicting the thermal resistance. \n",
    "\n",
    "Here, we aim to train GP adaptively to approximate the Tjmax=175 limit state.\n",
    "\n",
    "The difference is that we are employing the sparse GP as the surrogate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b6f4ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\CHSHGUO\\Anaconda3\\envs\\SciML\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\CHSHGUO\\Anaconda3\\envs\\SciML\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\CHSHGUO\\Anaconda3\\envs\\SciML\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import qmc, norm\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, max_error, brier_score_loss\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea94f231",
   "metadata": {},
   "source": [
    "### 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a467ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pool: 9421\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./Dataset/TcTj_train.csv', header=None)\n",
    "df.columns = ['Q1', 'Q2', 'd', 'b', 'L', 'c', 'L_duct', 'n', 't', 'xc1', 'yc1', 'xc2', 'yc2', 'Tc', 'Tj', 'w']\n",
    "print(f\"Pool: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd780065-62c1-49ef-b35f-a9c7c48ca451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered pol: 9386\n"
     ]
    }
   ],
   "source": [
    "# Remove outliers\n",
    "df = df[df.Tj<250].reset_index(drop=True)\n",
    "print(f\"Filtered pol: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef413e0d-18f2-4e05-a28e-2ec2b30e4d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered testing pool: 9375\n"
     ]
    }
   ],
   "source": [
    "# Dedicated testing set\n",
    "df_test = pd.read_csv('./Dataset/TcTj_test.csv', header=None)\n",
    "df_test.columns = ['Q1', 'Q2', 'd', 'b', 'L', 'c', 'L_duct', 'n', 't', 'xc1', 'yc1', 'xc2', 'yc2', 'Tc', 'Tj', 'w']\n",
    "\n",
    "# Remove outliers\n",
    "df_test = df_test[df_test.Tj<250].reset_index(drop=True)\n",
    "print(f\"Filtered testing pool: {df_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae4178b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_samples(df, train_num):\n",
    "   \n",
    "    # Create dataset\n",
    "    X = df.iloc[:, :-3].to_numpy()\n",
    "    y = df.iloc[:, -2].to_numpy()\n",
    "    \n",
    "    # Train-test split\n",
    "    if train_num < len(df):\n",
    "        test_size = 1-train_num/len(df)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    else:\n",
    "        X_train, y_train = X, y\n",
    "        X_test, y_test = None, None\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7786479d-29b2-41fa-a8cc-43881cf99208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X, _, y, _ = create_samples(df, 9000)\n",
    "X_test, _, y_test, _ = create_samples(df_test, 9000)\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3055a43e",
   "metadata": {},
   "source": [
    "### 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58670404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    \"\"\"This function is used for evaluating the ML models performance.\"\"\"\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    max_e = max_error(y_true, y_pred)\n",
    "    \n",
    "    percentage = np.abs(y_true-y_pred)/y_true\n",
    "    max_percentage = np.max(percentage)*100\n",
    "    max_percentage_loc = np.argmax(percentage)\n",
    "    mean_percentage = np.mean(percentage)*100\n",
    "    \n",
    "    return rmse, max_e, max_percentage, max_percentage_loc, mean_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c77e600-5d94-482a-8c7f-d61acd0d094a",
   "metadata": {},
   "source": [
    "#### GPflow setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9430bc04-3ad5-4c97-abf3-29fd8ebb0313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_length_scales(dim, n_restarts, initial_guess=None):\n",
    "    \n",
    "    # Random initial params\n",
    "    lb, ub = -2, 2\n",
    "    lhd = qmc.LatinHypercube(d=dim, seed=42).random(n_restarts)\n",
    "    lhd = (ub-lb)*lhd + lb\n",
    "    length_scales = 10**lhd\n",
    "\n",
    "    # Informed initial guess\n",
    "    if initial_guess is not None:\n",
    "        length_scales = np.vstack((length_scales, initial_guess))\n",
    "\n",
    "    return length_scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6241b766-2de4-4dea-9bd8-d06b36ac514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def create_induce_points(X, sample_num, sampling_scheme='LHS'):\n",
    "    \"\"\"Space-filling sampling for inducing points.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "    - X: the full training dataset\n",
    "    - sample_num: the number of training samples\n",
    "    - sampling_scheme: the sampling scheme\n",
    "    - verbose: print the information\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create virtual samples\n",
    "    if sampling_scheme == 'LHS':\n",
    "        raw_virtual_samples = qmc.LatinHypercube(d=X.shape[1]).random(n=sample_num)\n",
    "    elif sampling_scheme == 'Halton':\n",
    "        raw_virtual_samples = qmc.Halton(d=X.shape[1]).random(sample_num)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid sampling scheme: {sampling_scheme}\")\n",
    "\n",
    "    # Find closest real samples\n",
    "    sample_finder = NearestNeighbors(n_neighbors=1).fit(X)\n",
    "    _, indices = sample_finder.kneighbors(raw_virtual_samples)\n",
    "    \n",
    "    # Drop duplicates\n",
    "    train_indices = np.unique(indices)\n",
    "\n",
    "    # Compose train & pool samples\n",
    "    X_induce = X[train_indices.flatten()]\n",
    "  \n",
    "    return X_induce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d895448b-23c8-4cf0-abf0-f8bdc8903a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, X_induce, n_restarts=20, init_lengthscales=None, \n",
    "        init_variance=None, trainable=True, verbose=True):\n",
    "    \n",
    "    models = []\n",
    "    loss = []\n",
    "    \n",
    "    # Generate initial guesses for length scale\n",
    "    length_scales = init_length_scales(X.shape[1], n_restarts, init_lengthscales)\n",
    "    if init_variance is None:\n",
    "        variance=np.var(y_train)\n",
    "    else:\n",
    "        variance=init_variance\n",
    "\n",
    "    if not trainable:\n",
    "        model = gpflow.models.SGPR(\n",
    "            (X, y.reshape(-1, 1)),\n",
    "            kernel=kernel,\n",
    "            inducing_variable=X_induce,\n",
    "            mean_function=gpflow.functions.Polynomial(0)\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "    else:            \n",
    "        for i, init in enumerate(length_scales):\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"Performing {i+1}-th optimization:\")\n",
    "\n",
    "            # Set up the model\n",
    "            kernel = gpflow.kernels.SquaredExponential(variance=variance, lengthscales=init)\n",
    "            model = gpflow.models.SGPR(\n",
    "                (X, y.reshape(-1, 1)),\n",
    "                kernel=kernel,\n",
    "                inducing_variable=X_induce,\n",
    "                mean_function=gpflow.functions.Polynomial(0)\n",
    "            )\n",
    "\n",
    "            opt = gpflow.optimizers.Scipy()\n",
    "            loss_closure = model.training_loss_closure(compile=True)\n",
    "            opt.minimize(loss_closure, model.trainable_variables, options=dict(maxiter=100))\n",
    "\n",
    "            models.append(model)\n",
    "            loss.append(loss_closure().numpy())\n",
    "    \n",
    "        # Select the model with the highest log-marginal likelihood\n",
    "        best_model_index = np.argmin(loss)\n",
    "        best_model = models[best_model_index]\n",
    "\n",
    "        return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d54367-b787-405b-9e85-d859152f8c36",
   "metadata": {},
   "source": [
    "#### Active learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2cdd6f-ae56-49f0-a719-8f7d021b06d1",
   "metadata": {},
   "source": [
    "Select diverse batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10cc91c9-a4c3-4bc1-b038-1cd44bc499b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_diverse_batch(samples, acq, batch_size=5, pre_filter=False):\n",
    "    \n",
    "    if pre_filter:\n",
    "        thred = np.quantile(acq, pre_filter)\n",
    "        filtered_indices = np.arange(len(samples))[acq>thred]\n",
    "        samples = samples[acq>thred]\n",
    "        acq = acq[acq>thred]\n",
    "    \n",
    "    else:\n",
    "        filtered_indices = np.arange(len(samples))\n",
    "        \n",
    "    # Perform weighted K-means clustering on the samples\n",
    "    kmeans = KMeans(n_clusters=batch_size, n_init=10, random_state=0).fit(samples, sample_weight=acq)\n",
    "    cluster_labels = kmeans.labels_\n",
    "\n",
    "    # Find the highest acquisition value sample in each cluster\n",
    "    selected_indices = []\n",
    "    for cluster_idx in range(batch_size):\n",
    "        cluster_indices = np.where(cluster_labels == cluster_idx)[0]\n",
    "        cluster_acquisition_values = acq[cluster_indices]\n",
    "        best_index_in_cluster = cluster_indices[np.argmax(cluster_acquisition_values)]\n",
    "        selected_indices.append(best_index_in_cluster)\n",
    "\n",
    "    return filtered_indices[selected_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7b335b-7437-446a-be22-3c9dab1da9cc",
   "metadata": {},
   "source": [
    "Acquisition function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50ea9b55-8617-471a-b68b-3dfe8d3fbdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquisition(model, candidate, limit_state_value=0, batch_mode=False, batch_size=None):\n",
    "\n",
    "    # Compute prediction variance\n",
    "    f_mean, f_var = model.predict_f(candidate, full_cov=False)\n",
    "    f_mean = f_mean.numpy().flatten()\n",
    "    f_var = f_var.numpy().flatten()\n",
    "\n",
    "    # Calculate U values\n",
    "    U_values = np.abs(f_mean-limit_state_value)/np.sqrt(f_var)\n",
    "\n",
    "    # Sample selection\n",
    "    if batch_mode:\n",
    "        # Batch selection mode\n",
    "        U_normalied = MinMaxScaler().fit_transform(1/U_values.reshape(-1, 1))\n",
    "        indices = select_diverse_batch(candidate, U_normalied.flatten(), batch_size=batch_size)\n",
    "    \n",
    "    else:\n",
    "        # Single point selection mode\n",
    "        indices = np.argmin(U_values)\n",
    "\n",
    "    return U_values, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c143794-ddc6-4e7f-b616-ebb330174e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_creator(X, y, sample_num, sampling_scheme='LHS'):\n",
    "    \n",
    "    # Create virtual samples\n",
    "    if sampling_scheme == 'LHS':\n",
    "        raw_virtual_samples = qmc.LatinHypercube(d=X.shape[1]).random(n=sample_num)\n",
    "    elif sampling_scheme == 'Halton':\n",
    "        raw_virtual_samples = qmc.Halton(d=X.shape[1]).random(sample_num)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid sampling scheme: {sampling_scheme}\")\n",
    "\n",
    "    # Dataset statistics\n",
    "    X_scaled = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "    # Find closest real samples\n",
    "    sample_finder = NearestNeighbors(n_neighbors=1).fit(X_scaled)\n",
    "    _, indices = sample_finder.kneighbors(raw_virtual_samples)\n",
    "    \n",
    "    # Drop duplicates\n",
    "    indices = np.unique(indices)\n",
    "\n",
    "    # Select samples\n",
    "    selected_X = X[indices.flatten()]\n",
    "    selected_y = y[indices.flatten()]\n",
    "\n",
    "    # Identify remaining samples\n",
    "    all_indices = np.arange(X.shape[0])\n",
    "    remaining_indices = np.setdiff1d(all_indices, indices)\n",
    "    remaining_X = X[remaining_indices]\n",
    "    remaining_y = y[remaining_indices]\n",
    "  \n",
    "    return selected_X, selected_y, remaining_X, remaining_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7af04a1c-2a3a-439f-9bc7-30c982cf05e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_assessment(model, X_test, y_test, limit_state):\n",
    "    f_mean, f_var = model.predict_f(X_test, full_cov=False)\n",
    "    y_prob = norm.cdf(limit_state, loc=f_mean, scale=np.sqrt(f_var))\n",
    "    label = np.where(y_test > limit_state, 1, 0)\n",
    "    brier_score = brier_score_loss(label, 1-y_prob)\n",
    "    return brier_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72a411a1-c83d-443b-b0e3-3ed1db4c0d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial samples \n",
    "ini_sample_num = 300\n",
    "induce_points_num = 200 \n",
    "X_train, y_train, X_pool, y_pool = sample_creator(X, y, ini_sample_num, sampling_scheme='LHS')\n",
    "X_train_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c43c9ad-f0dc-4473-bcab-c97cb96a5a72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start 1th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 1: test brier score==>0.01933/0.01039, U==>0.0858/1.65, index==>[5165 1085 1011 7705 1647 7553 1244 8648 5573 7939]\n",
      "Start 2th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 2: test brier score==>0.01693/0.01039, U==>0.0013/1.65, index==>[3283 6079 2922  456 1530 7739  497  776 1439 6066]\n",
      "Start 3th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 3: test brier score==>0.01662/0.01039, U==>0.0105/1.65, index==>[1533 7536 2605 4908  610  260 4763 1699 2478 2708]\n",
      "Start 4th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 4: test brier score==>0.01645/0.01039, U==>0.0105/1.65, index==>[ 286 6435 4317 2715 3554 6491 8361 8067  322 5040]\n",
      "Start 5th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 5: test brier score==>0.01560/0.01039, U==>0.0230/1.65, index==>[5513 8256 6004 2607 4554  534 4390 8643 4403 5616]\n",
      "Start 6th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 6: test brier score==>0.01530/0.01039, U==>0.0240/1.65, index==>[2005 7029  742  998 8635 4481 7864  309 6951 4542]\n",
      "Start 7th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 7: test brier score==>0.01523/0.01039, U==>0.0273/1.65, index==>[2064 1364 6204 7705 8331 7183 7607 1319 1999 6894]\n",
      "Start 8th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 8: test brier score==>0.01424/0.01039, U==>0.0364/1.65, index==>[7004 5589 5734 7952  643 7059 4232 8233 6936 1265]\n",
      "Start 9th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 9: test brier score==>0.01298/0.01039, U==>0.0022/1.65, index==>[4841 1279 5305 5991 1926 4731 1242 5129  812 7133]\n",
      "Start 10th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 10: test brier score==>0.01411/0.01039, U==>0.0160/1.65, index==>[ 296 6608 3549 8623 2927 4622 6443 1134 6451  294]\n",
      "Start 11th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 11: test brier score==>0.01383/0.01039, U==>0.0213/1.65, index==>[7486 1296 6345 4550 2380 7797 6052 1212 6411 4153]\n",
      "Start 12th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 12: test brier score==>0.01330/0.01039, U==>0.0117/1.65, index==>[7263 3952 8153 6329 8593 6018  489  784 6757 6317]\n",
      "Start 13th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 13: test brier score==>0.01325/0.01039, U==>0.0200/1.65, index==>[1223 3088 4329 5182 2064 7940 5529 4866 8026 7006]\n",
      "Start 14th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 14: test brier score==>0.01327/0.01039, U==>0.0053/1.65, index==>[3865 7450 3810 7335 7394 4189 6617 2296 2437 4787]\n",
      "Start 15th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 15: test brier score==>0.01338/0.01039, U==>0.0205/1.65, index==>[  49   76 2384 3552 6561 7366  399 5275 7811 3718]\n",
      "Start 16th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 16: test brier score==>0.01303/0.01039, U==>0.0666/1.65, index==>[1475 4507 1934 6609 7367 6137 7785 5599 3238    6]\n",
      "Start 17th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 17: test brier score==>0.01262/0.01039, U==>0.0231/1.65, index==>[1522 6383 4619  830 1177 3519 5254  795 5487 8052]\n",
      "Start 18th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 18: test brier score==>0.01259/0.01039, U==>0.0063/1.65, index==>[6896 5062  186 8161 7803 2955 2856 7090 7766 5039]\n",
      "Start 19th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 19: test brier score==>0.01260/0.01039, U==>0.0935/1.65, index==>[ 979 5344 4639 4717 3406 1225 5297 1816 1624 4659]\n",
      "Start 20th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 20: test brier score==>0.01229/0.01039, U==>0.2213/1.65, index==>[8076 3412 1879 4023 7102 8406  216 2137 7626 5717]\n",
      "Start 21th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 21: test brier score==>0.01246/0.01039, U==>0.2502/1.65, index==>[ 766 4085 5180 8340 4236 2989   61 8418 1131 6211]\n",
      "Start 22th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 22: test brier score==>0.01225/0.01039, U==>0.5083/1.65, index==>[7098 7161  478 3888 7063 8212 4506 1177 5588 4145]\n",
      "Start 23th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 23: test brier score==>0.01225/0.01039, U==>0.6320/1.65, index==>[4150 7058 7483 4005 1478 1267 5907 4990 7184 8102]\n",
      "Start 24th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 24: test brier score==>0.01252/0.01039, U==>0.7533/1.65, index==>[4892 3574 7826 7763 7960 7172 2183 1258 5726   66]\n",
      "Start 25th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 25: test brier score==>0.01258/0.01039, U==>0.6741/1.65, index==>[7411 7308   69  946 2641  586 5499 7222 3488 7057]\n",
      "Start 26th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 26: test brier score==>0.01246/0.01039, U==>1.1024/1.65, index==>[1920 1593 4555 1631 5368 8361 5487 1138  508 7403]\n",
      "Start 27th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 27: test brier score==>0.01236/0.01039, U==>1.2290/1.65, index==>[6368 5347 5067 1863 2095 3583 6892 2028 3914 5596]\n",
      "Start 28th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 28: test brier score==>0.01234/0.01039, U==>1.6240/1.65, index==>[1439 3502 2865 6880  400 7977  647 3840 1458 3393]\n",
      "Start 29th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 29: test brier score==>0.01258/0.01039, U==>2.3578/1.65, index==>[3996  352 2800 4530 6278 4948 6397 2490 2508 5036]\n",
      "Start 30th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 30: test brier score==>0.01243/0.01039, U==>2.4776/1.65, index==>[7607 6818 6179 2155 7596 6563 6584 3267 4265  800]\n",
      "Start 31th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 31: test brier score==>0.01258/0.01039, U==>2.7198/1.65, index==>[2435  637 6795 5935 6038 1753 2443 5183 2173 2168]\n",
      "Start 32th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 32: test brier score==>0.01256/0.01039, U==>2.2864/1.65, index==>[ 494 6286 8001 2957 6129 4157 5428  683 6691  938]\n",
      "Start 33th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 33: test brier score==>0.01244/0.01039, U==>2.5362/1.65, index==>[1757  282 1527 4498 1847 7468  457 8180  566 5723]\n",
      "Start 34th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 34: test brier score==>0.01245/0.01039, U==>2.4558/1.65, index==>[7744 7627 4857 7166 3366 2176 2425  510  770  365]\n",
      "Start 35th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 35: test brier score==>0.01256/0.01039, U==>2.9463/1.65, index==>[7040 2323 3532 5988 2232 4319 2393 1421 1272 7358]\n",
      "Start 36th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 36: test brier score==>0.01230/0.01039, U==>2.6974/1.65, index==>[7689 2940 6740  435 7898 1179 6927 3689 6281 5892]\n",
      "Start 37th learning iteration:\n",
      "Good fitting. Proceed:\n",
      "Iter 37: test brier score==>0.01237/0.01039, U==>3.1629/1.65, index==>[7704 5257 7912 2504 1319  638  383  667 3381  464]\n",
      "CPU times: total: 18min 16s\n",
      "Wall time: 9min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "n_iter = 100\n",
    "U_hist, test_brier_scores = [], []\n",
    "Tjmax = 175\n",
    "success = 0\n",
    "\n",
    "with tf.device(\"CPU:0\"):\n",
    "    for i in range(n_iter):\n",
    "        print(f\"Start {i+1}th learning iteration:\")\n",
    "\n",
    "        # 0-Create indice points\n",
    "        X_induce = create_induce_points(X_train_scaled, induce_points_num, sampling_scheme='LHS')\n",
    "    \n",
    "        # 1-GP model training and predicting\n",
    "        if i == 0:\n",
    "            model = fit(X_train_scaled, y_train, X_induce, n_restarts=20, verbose=False)\n",
    "    \n",
    "        else:\n",
    "            # model = fit(X_train_scaled, y_train, n_restarts=20, verbose=False)\n",
    "            model = fit(X_train_scaled, y_train, X_induce, n_restarts=5, \n",
    "                        init_lengthscales=init_lengthscales, \n",
    "                        init_variance=init_variance, verbose=False)\n",
    "    \n",
    "        # 2-Check fitting results\n",
    "        f_mean, _ = model.predict_f(scaler.transform(X_test), full_cov=False)\n",
    "        has_nan = tf.reduce_any(tf.math.is_nan(f_mean)).numpy()\n",
    "        counter = 0\n",
    "        while has_nan:\n",
    "            print(f\"Bad fitting. Refit the data:\")\n",
    "            counter += 1\n",
    "            model = fit(X_train_scaled, y_train, X_induce, n_restarts=5, verbose=False)\n",
    "            f_mean, _ = model.predict_f(scaler.transform(X_test), full_cov=False)\n",
    "            has_nan = tf.reduce_any(tf.math.is_nan(f_mean)).numpy()\n",
    "    \n",
    "            if counter > 4:\n",
    "                print(f\"Fallback to parameters from last iteration:\")\n",
    "                model = fit(X, y, X_induce, n_restarts=1, \n",
    "                            init_lengthscales=init_lengthscales.flatten(), init_variance=init_variance, \n",
    "                            trainable=False, verbose=False)\n",
    "                f_mean, _ = model.predict_f(scaler.transform(X_test), full_cov=False)\n",
    "                has_nan = tf.reduce_any(tf.math.is_nan(f_mean)).numpy()\n",
    "    \n",
    "        print(f\"Good fitting. Proceed:\")\n",
    "    \n",
    "        # 3-Model assessment\n",
    "        brier_score = confidence_assessment(model, scaler.transform(X_test), y_test, Tjmax)\n",
    "        test_brier_scores.append(brier_score)\n",
    "    \n",
    "        # 4-Acquisition\n",
    "        X_pool_scaled = scaler.transform(X_pool)\n",
    "        U_values, indices = acquisition(model, X_pool_scaled, limit_state_value=Tjmax, batch_mode=True, batch_size=10)\n",
    "        target = np.min(U_values[indices])\n",
    "        U_hist.append(target)\n",
    "        print(f\"Iter {i+1}: test brier score==>{brier_score:.5f}/{0.01039}, U==>{target:.4f}/1.65, index==>{indices}\")\n",
    "    \n",
    "        if target >= 3:\n",
    "            # success += 1\n",
    "\n",
    "            # if success > 5:\n",
    "            break\n",
    "    \n",
    "        # 5-Updating\n",
    "        X_train = np.vstack((X_train, X_pool[indices]))\n",
    "        X_train_scaled = scaler.transform(X_train)\n",
    "        y_train = np.append(y_train, y_pool[indices])\n",
    "    \n",
    "        # Update pool\n",
    "        X_pool = np.delete(X_pool, obj=indices, axis=0)\n",
    "        y_pool = np.delete(y_pool, obj=indices, axis=0)\n",
    "    \n",
    "        # Update initial guess\n",
    "        init_lengthscales = model.kernel.lengthscales.numpy().reshape(1, -1)\n",
    "        init_variance = model.kernel.variance.numpy().flatten()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b795b263-8c61-44ff-99c4-dd5b9d6f242e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 80.713,  79.218,  77.826, 147.82 , 139.78 , 187.26 ,  78.498,\n",
       "        91.657, 100.78 , 108.19 ,  86.428,  88.56 , 112.41 , 118.32 ,\n",
       "        50.75 ,  96.587, 132.38 ,  96.794,  55.769, 124.6  , 134.9  ,\n",
       "        92.656, 126.11 ,  69.143, 115.34 ,  91.974, 100.22 ,  78.026,\n",
       "       193.   ,  83.936,  77.058,  72.499, 103.53 , 121.3  , 126.41 ,\n",
       "       125.21 , 126.53 , 102.21 ,  82.855,  93.891, 142.59 ,  81.103,\n",
       "        71.473, 111.62 ,  92.533, 116.29 ,  79.948, 151.77 , 173.31 ,\n",
       "       109.66 , 107.17 , 111.09 ,  81.773, 108.09 , 113.41 ,  54.075,\n",
       "        82.608, 236.38 , 116.97 , 123.49 , 144.37 ,  93.917, 102.37 ,\n",
       "        90.742, 126.68 ,  91.834, 120.15 , 133.48 ,  92.195,  96.571,\n",
       "       109.55 ,  76.912,  83.666,  74.07 ,  98.07 , 121.72 , 117.39 ,\n",
       "       148.03 , 148.95 , 110.92 , 165.21 , 120.18 ,  98.328, 149.81 ,\n",
       "        84.273,  45.988,  57.86 , 105.66 ,  58.323, 191.55 , 145.69 ,\n",
       "       112.14 , 162.34 , 150.78 , 141.94 ,  70.005, 103.08 , 107.2  ,\n",
       "       102.48 , 124.39 , 120.5  , 167.7  , 152.72 , 145.81 ,  70.141,\n",
       "        81.085,  77.65 ,  73.537,  84.69 , 116.62 , 175.49 , 103.02 ,\n",
       "       109.06 ,  83.369,  76.342, 109.14 ,  83.384,  67.782,  62.426,\n",
       "        97.533, 110.41 , 125.84 , 153.62 ,  56.109, 120.81 ,  97.693,\n",
       "       121.14 ,  83.602, 111.12 , 109.83 , 105.44 ,  98.491,  90.019,\n",
       "       183.77 ,  60.567,  67.544, 138.08 , 144.4  ,  95.559, 120.39 ,\n",
       "       137.9  ,  83.915,  98.217, 137.95 , 132.24 , 145.18 ,  97.153,\n",
       "       109.05 , 152.38 ,  59.55 ,  92.523, 116.56 , 141.46 , 142.05 ,\n",
       "        69.669,  91.106, 118.36 ,  57.489,  62.712, 101.27 ,  87.628,\n",
       "       135.28 ,  63.326, 108.44 , 151.56 , 119.33 ,  84.517, 138.09 ,\n",
       "        94.265, 138.7  , 107.94 , 159.08 ,  69.648, 121.29 , 159.96 ,\n",
       "       124.27 ,  86.214,  71.445, 146.74 ,  72.523,  86.24 , 109.39 ,\n",
       "       162.84 ,  88.239,  59.443,  91.709,  77.139,  76.052,  92.581,\n",
       "        84.408, 138.91 , 127.41 ,  56.77 ,  93.655, 160.37 , 143.12 ,\n",
       "        68.324,  98.899, 112.18 ,  94.808,  55.725, 146.37 ,  78.121,\n",
       "       150.29 , 137.37 ,  68.882,  75.391,  97.123,  97.342,  94.234,\n",
       "        56.658,  82.456, 128.18 ,  95.088, 162.27 , 102.62 ,  68.724,\n",
       "       111.68 ,  99.752, 104.72 ,  46.045, 150.   ,  87.972, 128.77 ,\n",
       "        96.807, 120.91 ,  62.241, 110.12 , 159.27 , 173.55 , 112.14 ,\n",
       "       216.51 , 129.99 , 108.83 , 120.38 , 127.61 , 100.15 ,  48.143,\n",
       "       143.93 ,  68.066, 120.02 ,  92.168, 141.94 ,  91.443,  87.085,\n",
       "       141.69 , 104.78 ,  87.311,  75.771, 112.35 , 127.21 ,  92.986,\n",
       "        99.957, 141.58 , 132.1  , 112.31 , 194.64 , 101.27 ,  99.17 ,\n",
       "       121.56 ,  55.711,  88.985, 212.06 ,  84.511, 114.39 ,  98.27 ,\n",
       "       147.21 , 119.47 , 132.56 ,  67.446,  49.78 ,  94.529,  86.498,\n",
       "       136.9  ,  82.453,  81.626,  94.971,  98.396, 118.21 , 123.75 ,\n",
       "       144.31 , 188.22 , 197.15 , 232.03 , 217.16 , 194.35 , 197.08 ,\n",
       "       177.59 , 160.77 , 183.21 , 165.52 , 162.51 , 206.79 , 169.2  ,\n",
       "       157.74 , 225.49 , 210.51 , 168.74 , 181.55 , 168.5  , 155.43 ,\n",
       "       209.3  , 196.66 , 178.93 , 145.84 , 179.85 , 162.55 , 151.33 ,\n",
       "       182.05 , 177.26 , 188.2  , 186.08 , 183.4  , 185.74 , 156.24 ,\n",
       "       182.94 , 178.59 , 182.7  , 135.89 , 175.32 , 129.51 , 200.96 ,\n",
       "       176.23 , 168.25 , 175.05 , 151.33 , 157.12 , 187.56 , 193.59 ,\n",
       "       161.55 , 133.02 , 194.69 , 166.34 , 174.37 , 211.   , 157.62 ,\n",
       "       158.99 , 174.78 , 148.99 , 161.07 , 166.96 , 194.92 , 152.33 ,\n",
       "       165.71 , 174.96 , 159.74 , 172.54 , 190.26 , 141.96 , 155.71 ,\n",
       "       168.94 , 214.29 , 132.13 , 130.96 , 159.31 , 157.47 , 242.29 ,\n",
       "       195.48 , 202.17 , 152.26 , 165.36 , 172.13 , 226.   , 205.09 ,\n",
       "       179.13 , 164.   , 171.88 , 181.31 , 217.06 , 125.77 , 200.93 ,\n",
       "       156.34 , 152.99 , 195.64 , 207.31 , 167.19 , 195.87 , 160.12 ,\n",
       "       155.66 , 169.9  , 193.77 , 130.12 , 170.03 , 170.89 , 160.52 ,\n",
       "       165.06 , 147.03 , 180.9  , 193.5  , 178.13 , 228.32 , 172.27 ,\n",
       "       126.55 , 159.68 , 147.49 , 174.71 , 168.4  , 194.43 , 190.12 ,\n",
       "       184.04 , 194.64 , 166.26 , 161.23 , 188.08 , 183.56 , 187.81 ,\n",
       "       197.37 , 168.59 , 169.43 , 178.29 , 128.95 , 150.33 , 155.05 ,\n",
       "       166.14 , 195.03 , 159.52 , 164.91 , 146.73 , 184.78 , 171.91 ,\n",
       "       164.66 , 160.52 , 164.87 , 157.58 , 133.66 , 164.69 , 153.08 ,\n",
       "       190.77 , 145.95 , 151.81 , 165.22 , 203.41 , 206.47 , 133.44 ,\n",
       "       145.73 , 151.92 , 152.37 , 185.78 , 249.3  , 179.7  , 182.84 ,\n",
       "       145.97 , 179.78 , 172.01 , 158.35 , 171.26 , 157.94 , 157.18 ,\n",
       "       140.42 , 158.94 , 165.26 , 180.6  , 174.98 , 234.95 , 177.85 ,\n",
       "       161.   , 154.89 , 162.89 , 162.93 , 197.31 , 160.51 , 179.84 ,\n",
       "       159.74 , 148.19 , 151.52 , 136.9  , 167.82 , 187.4  , 172.58 ,\n",
       "       140.5  , 177.66 , 161.83 , 163.81 , 153.41 , 151.31 , 131.27 ,\n",
       "       136.95 , 160.1  , 143.39 , 165.45 , 181.52 , 180.24 , 133.62 ,\n",
       "       187.88 , 165.91 , 156.96 , 236.63 , 170.87 , 140.17 , 164.58 ,\n",
       "       153.78 , 156.84 , 172.88 , 169.33 , 167.51 , 165.26 , 103.2  ,\n",
       "       184.85 , 166.53 , 169.01 , 112.44 , 174.17 , 162.84 , 223.53 ,\n",
       "       162.24 , 183.75 , 132.76 , 145.68 , 140.24 , 147.06 , 182.14 ,\n",
       "       145.22 , 141.37 , 152.7  , 156.7  , 158.6  , 155.54 , 151.86 ,\n",
       "       149.64 , 171.72 , 159.61 , 157.   , 163.22 , 125.64 , 163.75 ,\n",
       "       124.44 , 192.37 , 169.91 , 163.98 , 179.59 , 165.3  , 196.92 ,\n",
       "       163.69 , 170.55 , 131.18 , 151.6  , 143.58 , 199.74 , 168.35 ,\n",
       "       159.48 , 153.8  , 177.73 , 166.12 , 158.22 , 188.45 , 180.52 ,\n",
       "       175.7  , 176.11 , 129.99 , 184.43 , 170.66 , 159.41 , 144.47 ,\n",
       "       161.6  , 149.84 , 151.63 , 154.05 , 146.8  , 143.49 , 181.75 ,\n",
       "       162.49 , 148.9  , 128.24 , 157.64 , 193.54 , 168.15 , 172.58 ,\n",
       "       197.53 , 146.24 , 172.3  , 157.34 , 141.13 , 185.2  , 150.41 ,\n",
       "       139.65 , 177.46 , 149.79 ,  63.593, 146.4  , 181.06 , 188.38 ,\n",
       "       106.22 , 155.24 , 151.7  , 145.27 , 164.75 , 178.82 , 192.62 ,\n",
       "       149.63 , 240.79 , 183.59 , 173.61 , 159.68 , 145.44 , 146.85 ,\n",
       "       125.32 , 129.86 , 135.59 , 172.14 , 178.69 , 162.94 , 156.63 ,\n",
       "       149.29 , 166.88 , 145.94 , 138.55 , 171.34 , 175.97 , 182.53 ,\n",
       "        49.206, 147.05 , 153.36 , 155.69 , 124.73 , 153.53 , 162.71 ,\n",
       "       209.15 , 151.37 , 237.91 , 144.68 , 130.65 , 148.68 , 143.3  ,\n",
       "       189.17 , 185.32 , 113.85 , 222.71 , 150.56 , 170.82 , 153.34 ,\n",
       "       154.94 , 126.46 , 142.57 , 173.35 , 190.25 , 156.43 , 141.94 ,\n",
       "       166.81 , 146.58 , 161.07 ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc35a7bf-effd-4a0d-abbc-df4b379273aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.cdf(-1.65, loc=0, scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8397e55a-46a2-47e2-9a88-f99e9cbbb561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 13)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d3249a-ee05-4fb1-b764-8f6fb6e67bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "import pickle\n",
    "with open('AL_model_params.pickle', 'wb') as handle:\n",
    "    pickle.dump(gpflow.utilities.parameter_dict(model), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Save training data\n",
    "np.save('AL_X_train.npy', X_train)\n",
    "np.save('AL_y_train.npy', y_train)\n",
    "\n",
    "# Save history\n",
    "df = pd.DataFrame({\"U\": np.array(U_hist), \"brier_scores\": np.array(test_brier_scores)})\n",
    "df['benchmark'] = 0.01039\n",
    "df.to_csv(\"AL_history.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfdc6d8-19fe-41d1-8a71-e7f09771fadf",
   "metadata": {},
   "source": [
    "#### Propose solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ff05a9-e256-41c9-b0a1-7b4f94f9889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidates = pd.read_csv('./Dataset/candidates.csv')\n",
    "df_candidates.columns = ['d', 'b', 'L', 'c', 'L_duct', 'n', 't', 'xc1', 'yc1', 'xc2', 'yc2']\n",
    "print(f\"PCandidate pool: {df_candidates.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3439ccb-e2ec-43a3-a673-4ac3abcc4050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_weight(X):\n",
    "    # Properties\n",
    "    density_Al = 2700\n",
    "    Fan_height = 40e-3\n",
    "    Fan_Weight = 50.8e-3\n",
    "    N_fan = np.ceil(X[:, 3] / Fan_height)\n",
    "\n",
    "    # Weight calculation\n",
    "    w = density_Al*(X[:, 3]*X[:, 2]*X[:, 4]+X[:, 7]*(X[:, 5]*X[:, 8]*X[:, 4]))+ Fan_Weight*N_fan\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebc86f7-c9e7-4733-a132-4982dd7f1e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_df = pd.read_csv('./Dataset/Q_test_locations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623be34c-abcf-4c91-9f29-f17469b20900",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (Q1, Q2) in enumerate(zip(Q_df['Q1'].to_numpy(), Q_df['Q2'].to_numpy())):\n",
    "\n",
    "    print(f\"Handling {i+1}th condition:\")\n",
    "    \n",
    "    # Compile feature samples\n",
    "    Q1_array, Q2_array = Q1*np.ones((df_candidates.shape[0], 1)), Q2*np.ones((df_candidates.shape[0], 1))\n",
    "    X_candidates = df_candidates.to_numpy()\n",
    "    X_candidates = np.hstack((Q1_array, Q2_array, X_candidates))\n",
    "    X_candidates_scaled = scaler.transform(X_candidates)\n",
    "\n",
    "    # GP prediction\n",
    "    f_mean, f_var = model.predict_f(X_candidates_scaled, full_cov=False)\n",
    "    f_mean = f_mean.numpy().flatten()\n",
    "    f_var = f_var.numpy().flatten()\n",
    "\n",
    "    # Utility\n",
    "    Tjmax = 175\n",
    "    likelihood = norm.cdf(Tjmax, loc=f_mean, scale=np.sqrt(f_var))\n",
    "    w = evaluate_weight(X_candidates)\n",
    "    utility = likelihood*1/w\n",
    "\n",
    "    # Sort candidates\n",
    "    df = pd.DataFrame(X_candidates)\n",
    "    df.columns = ['Q1', 'Q2', 'd', 'b', 'L', 'c', 'L_duct', 'n', 't', 'xc1', 'yc1', 'xc2', 'yc2']\n",
    "    df['weight'] = w\n",
    "    df['pred_T'] = f_mean\n",
    "    df['utility'] = utility\n",
    "    df_sorted = df.sort_values(by='utility', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Output results\n",
    "    df_reduced = df_sorted.iloc[:20, :].reset_index(drop=True)\n",
    "    df_reduced.to_csv(f\"Exp_{i+1}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a585b1f-78a5-4e02-8b64-a59777b9be1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
